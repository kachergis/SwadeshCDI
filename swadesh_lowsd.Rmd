---
title: "swadesh_lowsd"
author: "Alvin Tan"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r, include=F}
require(here)
require(glue)
require(tidyverse)
require(mirt)
options(dplyr.summarise.inform = FALSE)
theme_set(theme_classic())
set.seed(42)
```

Set up data variables
```{r}
languages <- list.files("data/all_forms") |> str_sub(end = -10)
gen_langs <- c("Finnish",
               "Kigiriama",
               "American Sign Language",
               "Greek (Cypriot)",
               "Spanish (Peruvian)",
               "British Sign Language",
               "Persian",
               "Kiswahili",
               "English (Irish)",
               "Irish",
               "Spanish (Chilean)")
train_langs <- setdiff(languages, gen_langs)

xldf <- readRDS("data/xldf_prod_allforms.rds")
d_prodl <- readRDS("data/allforms_prod_per_lang.rds")
category_proportions <- read_csv("data/category_proportions.csv")
```

```{r}
xldf_clean <- xldf |> 
  filter(!is.na(uni_lemma), !is.na(d)) |> 
  mutate(category = case_when(
    category == "descriptive_words (adjectives)" ~ "descriptive_words",
    category == "outside_places" ~ "outside",
    .default = category))

prod_pars <- xldf_clean |> 
  arrange(language, uni_lemma, desc(a1)) |> # get most discriminating uni_lemma per lang
  select(uni_lemma, language, uid, category, language, d) |>
  group_by(uni_lemma, language) |>
  slice(1)

xldf_train <- xldf_clean |> 
  filter(language %in% train_langs)

# ul_cats <- xldf_train |> 
#   group_by(uni_lemma, category) |> 
#   summarise(n = n()) |> 
#   arrange(desc(n)) |> 
#   slice(1) |> 
#   select(-n)
# 
# unis <- xldf_train |> 
#   filter(uni_lemma != "NA") |> 
#   group_by(uni_lemma) |>
#   summarise(d_m = mean(d), a1_m = mean(a1), 
#             d_sd = sd(d), a1_sd = sd(a1), 
#             n = language |> unique() |> length()) |> 
#   left_join(ul_cats, by = "uni_lemma")
```

Function to get correlations with total sumscore
```{r}
get_sumscore_cor <- function(xldf, d_prodl, languages, swad_unis) {
  xx <- list()
  for(lang in languages) {
    swad_l <- xldf |> 
      filter(language == lang, uni_lemma %in% swad_unis)
    if (nrow(swad_l) == 0) {
      xx <- c(xx, list(tibble(language = lang, cor = NA, num_overlap = nrow(swad_l))))
      next
    } else if (nrow(swad_l) == 1) {
      d_prodl_sub <- d_prodl[[lang]][,swad_l$uid]
    } else {
      d_prodl_sub <- rowMeans(d_prodl[[lang]][,swad_l$uid], na.rm=T)
    }
    swad_cor <- cor(rowMeans(d_prodl[[lang]], na.rm=T),  d_prodl_sub, use="na.or.complete")
    
    xx <- c(xx, list(tibble(language = lang, cor = swad_cor, num_overlap = nrow(swad_l))))
  }
  return(xx |> bind_rows())
}
```

```{r}
list_size <- 100
rand_comparisons <- 100
gen_res <- list()

prod_sum <- prod_pars |> 
  filter(language %in% train_langs) |> 
  group_by(uni_lemma) |> 
  summarise(num_langs = n(),
            mean_d = mean(d, na.rm=T),
            sd_d = sd(d, na.rm=T))
prod_cors <- lapply(2:(length(train_langs)), \(k) {
  prod_subset <- prod_sum |> 
    filter(num_langs >= k) |> 
    arrange(sd_d) |> 
    slice(1:list_size)
  swad_sumscore_cor <- get_sumscore_cor(xldf_clean, d_prodl, gen_langs, prod_subset$uni_lemma) |> 
    mutate(run = NA, sublist = "Swadesh")
  
  rand_subk <- prod_sum |> 
    filter(num_langs >= k)
  rand_sumscore_cors <- lapply(1:rand_comparisons, \(comp) {
    rand_idx <- sample(1:nrow(rand_subk), min(list_size, nrow(rand_subk)))
    rand_subset <- rand_subk |> 
      slice(rand_idx)
    rand_sumscore_cor <- get_sumscore_cor(xldf_clean, d_prodl, gen_langs, rand_subset$uni_lemma) |> 
      mutate(run = comp, sublist = "Random")
  }) |> bind_rows()
  
  bind_rows(swad_sumscore_cor, rand_sumscore_cors) |> 
    mutate(k = k)
}) |> bind_rows()


for(test_lang in gen_langs) {
  prod_test <- prod_pars |> 
    filter(language == test_lang)
  prod_cors <- sapply(2:(length(train_langs)), \(k) {
    prod_subset <- prod_sum |> 
      filter(num_langs >= k) |> 
      arrange(sd_d) |> 
      slice(1:list_size)
    prod_res <- prod_subset |> 
      left_join(prod_test, by = "uni_lemma")
    c((!is.na(prod_res$d)) |> sum(),
      tryCatch(cor(prod_res$mean_d, prod_res$d, use = "complete.obs"),
               error = \(err) NA))
  }) |> t() |> 
    `colnames<-`(c("num_overlap", "cor")) |> 
    as_tibble() |> 
    mutate(run = NA,
           k = 2:(length(train_langs)),
           language = test_lang,
           sublist = "Swadesh")
  
  rand_cors <- lapply(2:(length(train_langs)), \(k) {
    rand_subk <- prod_sum |> 
      filter(num_langs >= k)
    rand_cors <- sapply(1:rand_comparisons, \(comp) {
      rand_idx <- sample(1:nrow(rand_subk), min(list_size, nrow(rand_subk)))
      rand_res <- rand_subk |> 
        slice(rand_idx) |> 
        left_join(prod_test, by = "uni_lemma")
      c((!is.na(rand_res$d)) |> sum(),
        tryCatch(cor(rand_res$mean_d, rand_res$d, use = "complete.obs"),
                 error = \(err) NA))
    }) |> t() |> 
      `colnames<-`(c("num_overlap", "cor")) |> 
      as_tibble() |> 
      mutate(run = 1:rand_comparisons,
             k = k)
  }) |> 
    bind_rows() |> 
    mutate(language = test_lang,
           sublist = "Random")
  
  gen_res <- c(gen_res, list(bind_rows(prod_cors, rand_cors)))
}
gen_res <- bind_rows(gen_res)
```

```{r}
gen_cor_sum <- prod_cors |> 
  group_by(k, language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            cor = mean(cor)) |> 
  mutate(cor_f = atanh(cor))

gen_res_sum <- gen_res |> 
  group_by(k, language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            cor = mean(cor)) |> 
  mutate(cor_f = atanh(cor))
```

```{r}
ggplot(gen_res_sum,
       aes(x = k, y = cor, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(x = "k",
       y = "Correlation",
       col = "Sublist") +
  theme(legend.position = "bottom")
```

```{r}
ggplot(gen_cor_sum,
       aes(x = k, y = cor, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(x = "k",
       y = "Correlation",
       col = "Sublist") +
  theme(legend.position = "bottom")
```

Using category proportions to sample
```{r}
category_proportions <- read_csv("data/category_proportions.csv")
category_table <- category_proportions |> 
  mutate(n_per_cat_est = mean_prop * list_size,
         n_per_cat = floor(n_per_cat_est),
         remainder = n_per_cat_est %% 1) |> 
  arrange(desc(remainder)) |> 
  mutate(correction = c(rep(1, list_size - sum(n_per_cat)), 
                        rep(0, nrow(category_proportions) + sum(n_per_cat) - list_size)),
         n_per_cat = n_per_cat + correction) |> 
  select(category, n_per_cat)

cat_modal <- xldf_train |> 
  select(uni_lemma, category) |> 
  table() |> 
  as.data.frame() |> 
  arrange(desc(Freq)) |> 
  group_by(uni_lemma) |> 
  slice(1)

prod_cors_cat <- lapply(2:(length(train_langs)), \(k) {
  prod_subset <- prod_sum |> 
    filter(num_langs >= k) |> 
    arrange(sd_d) |> 
    left_join(cat_modal |> select(uni_lemma, category), by = "uni_lemma") |> 
    nest(unis = -category) |> 
    left_join(category_table, by = "category") |> 
    filter(category %in% category_table$category) |> 
    mutate(unis = map2(unis, n_per_cat, \(u, n) {u |> slice(1:n)})) |> 
    unnest(cols = "unis")
  swad_sumscore_cor <- get_sumscore_cor(xldf_clean, d_prodl, gen_langs, prod_subset$uni_lemma) |> 
    mutate(run = NA, sublist = "Swadesh")
  
  rand_subk <- prod_sum |> 
    filter(num_langs >= k)
  rand_sumscore_cors <- lapply(1:rand_comparisons, \(comp) {
    rand_idx <- sample(1:nrow(rand_subk), min(list_size, nrow(rand_subk)))
    rand_subset <- rand_subk |> 
      slice(rand_idx)
    rand_sumscore_cor <- get_sumscore_cor(xldf_clean, d_prodl, gen_langs, rand_subset$uni_lemma) |> 
      mutate(run = comp, sublist = "Random")
  }) |> bind_rows()
  
  bind_rows(swad_sumscore_cor, rand_sumscore_cors) |> 
    mutate(k = k)
}) |> bind_rows()
```

```{r}
gen_cor_cat <- prod_cors_cat |> 
  group_by(k, language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            cor = mean(cor)) |> 
  mutate(cor_f = atanh(cor))

ggplot(gen_cor_cat,
       aes(x = k, y = cor, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(x = "k",
       y = "Correlation",
       col = "Sublist") +
  theme(legend.position = "bottom")
```



Test information
```{r}
get_test_info <- function(xldf, languages, swad_list) {
  theta_range <- matrix(seq(-4,4,.01))
  xx <- tibble()
  
  for(lang in languages) {
    # message(glue("Processing {lang}\r"))
    model <- readRDS(glue("data/prod_models/{lang}_2PL_allforms_prod_fits.rds"))$model
    
    xldf_l <- xldf |> filter(language == lang)
    
    swad_idx <- is.element(xldf_l$uni_lemma, swad_list) |> which()
    swad_d <- xldf_l[swad_idx,] |> pull(d) |> mean(na.rm = TRUE)
    
    
    swad_tinfo <- testinfo(model, theta_range,
                           which.items = swad_idx) |> sum()
    
    test_info <- tibble(value = swad_tinfo, N = length(swad_idx), 
                        mean_d = swad_d, language = lang)
    
    xx <- xx |> bind_rows(test_info)
    
  }
  return(xx)
}

```



Number of forms penalty: DO NOT USE
```{r}
weights = c(1.0, 2.0, 4.0, 8.0, 16.0, 32.0)
tinfos <- list()

for (weight in weights) {
  prod_nform <- prod_sum |> 
    mutate(obj = sd_d + weight/num_langs)
  prod_nform_subset <- prod_nform |> 
    arrange(obj) |> 
    slice(1:list_size)
  tinfo <- get_test_info(xldf, train_langs, prod_nform_subset$uni_lemma)
  
  tinfos <- c(tinfos, 
              list(list(weight = weight,
                        swad_list = prod_nform_subset,
                        tinfo = tinfo)))
}

weights_2 = c(64.0, 128.0, 256.0, 512.0)
tinfos_2 <- list()

for (weight in weights_2) {
  prod_nform <- prod_sum |> 
    mutate(obj = sd_d + weight/num_langs)
  prod_nform_subset <- prod_nform |> 
    arrange(obj) |> 
    slice(1:list_size)
  tinfo <- get_test_info(xldf, train_langs, prod_nform_subset$uni_lemma)
  
  tinfos_2 <- c(tinfos_2, 
              list(list(weight = weight,
                        swad_list = prod_nform_subset,
                        tinfo = tinfo)))
}
```

```{r}
for (t in tinfos) {t$tinfo$value |> sum() |> print()}
for (t in tinfos_2) {t$tinfo$value |> sum() |> print()}
```


