---
title: "Measuring a Basic Developmental Vocabulary Across Many Languages"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf George Kachergis (kachergis@stanford.edu)} 
    \AND {\large \bf Virginia A. Marchman (marchman@stanford.edu)} 
    \AND {\large \bf Michael C. Frank (mcfrank@stanford.edu)} \\ Department of Psychology, 450 Jane Stanford Way \\ Stanford, CA 94305 USA}

abstract: >
    Early language skill is predictive of later life outcomes, and is thus of great interest to
    developmental psychologists and clinicians. The Communicative Development Inventories (CDIs),
    including a parent-reported inventory of early-learned vocabulary items, has proven to be
    a valid and reliable instrument for measuring children's early language skill. CDIs have been
    adapted to dozens of languages, and cross-linguistic comparisons thus far show both consistency 
    and variability in language acquisition trajectories. Here, we use item-response theory
    models trained on 26 languages to examine the psychometric properties of translation-equivalent concepts  
    that are frequently included on CDIs, with the goal of identifying a short list of
    concepts that are of similar learning difficulty in the majority of the languages, in order
    to propose a pool list of 'universal' words that can be used as a starting point for future CDI adaptations.
    After identifying a list of 96 items, we test how well this list generalizes to an additional 8 languages.
    
keywords: >
    early language learning; CDI; psychometrics; cross-linguistic comparison; Swadesh vocabulary;
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(xtable)
require(mirt)
require(tidyverse)
require(ggpubr)
require(tidyboot)
require(here)
```

# Introduction


<!-- REWRITE INTRO -->
Assessing children's early language skill is important for researchers, clinicians and parents, as early language skill is predictive of educational outcomes years later.
The MacArthur-Bates Communicative Development Inventories [CDIs; @Fenson2007] are a set of parent report forms that offer a holistic assessment of children's productive and receptive language skills.
CDIs are low-cost to administer and produce reliable and valid estimates of early vocabulary and other aspects of early language [@fenson1994]. 
The CDIs offer more comprehensive data than a short interaction in the lab with a child [@Fenson2000], because they ask parents to report on vocabulary comprehension as well as production, and other milestones, such as communicative gesture use and use of word combinations. 
Vocabulary size is assessed via a checklist format, which allows caregivers to quickly scan and recognize words their child produces or understands, rather than relying on recall alone. 
Because of these properties, CDI forms have been adapted to dozens of languages. 
Data from CDIs are archived in a central repository [Wordbank; @frank2017], and insights from these data have been used to inform theories of early language learning [@frank2021]. 

Although CDIs measure several constructs related to early language, we focus here on vocabulary assessment. 
Across languages, measures of vocabulary on the CDIs are very tightly correlated with other aspects of early language like gesture and grammatical competence [@bates1994; @frank2021]. 
These studies indicate that the language system looks to be "tightly woven" [@frank2021], in the sense that early vocabulary size serves as a good proxy measure of children's overall language skill. 

The American English CDI Words & Sentences (CDI:WS) form, targeting children 16-30 months of age, is comprised of 680 words from 22 semantic categories representing common early-learned words, including nouns (subdivided into e.g., Body Parts, Toys, and Clothing), action words (e.g. verbs), descriptive words (e.g. adjectives), and closed-class words such as pronouns.
Researchers have adapted the CDI:WS to many other languages: to date, Wordbank contains contributed datasets from 34 CDI:WS adaptations, and 28 adaptations of the CDI Words & Gestures (CDI:WG) form, which target younger children (8- to 16-month-olds) and are typically $\sim400$ words.

Although the CDIs have many advantages, one drawback is that it is difficult for researchers to adapt a CDI for a new language.
Indeed, there is no standardized process for adapting a CDI, but the process usually requires years of effort by researchers who are native speakers of a language for which there is no CDI, to first select and translate words that are appropriate for the intended language, and to then iteratively add, refine, and pilot the nascent CDI. [any testimonial on how long this can take, or how many pilot subjects might be needed?]

Shortened versions of the CDI have been proposed, and might seem a good place to start when looking for essential words to include on a CDI.
The 100-item short-form CDIs [@Fenson2000; @Fenson2007] are derived from the 680-item American English CDI:WS form, with items selected based on difficulty and item-to-full score correlations, while also attempting to represent the diversity of semantic and linguistic categories.
While the scores of the short-form CDI:WS are highly correlated with scores on the full CDI:WS, there is evidence for a ceiling effect for children older than 27 or 28 months of age. 
Moreover, it is unclear that the short-form items would generalize well to languages beyond English, as this was not a considered during their selection.

Other efforts to create short CDIs have leveraged Item-Response Theory [IRT; @embretson2013] models, which infer both the abilities of test takers and the difficulty of individual test items (i.e., words), along standardized dimensions.
IRT models have the potential to not only yield more accurate measures of children's language ability, but also to enable the construction of Computerized Adaptive Tests (CATs), which choose the next test item based on the responses to the previous items, and thus queickly hone in on the test-takers language ability.
CAT-based CDIs presenting 50 or fewer items have been found strongly correlate with scores on the full CDI:WS [@Makransky2016;@mayor2019;@chai2020], and a general method for creating CDI CATs that work well across a broader age range (12-36 months) has been proposed, and tested for American English and Mexican Spanish [@Kachergis2022]. 
However, the IRT model driving each CAT needs to be trained on a large and normative dataset, which may not be available in a given language.
To date, the IRT models are also fitted separately for each language, and the fitted parameters (e.g., word difficulty) are likely to vary across languages.

The goal of the current study is to examine whether there might be a core set of concepts that are frequently included on CDIs, and--importantly--that are of roughly equal difficulty across many languages.
Taking inspiration from the fields of lexicostatistics and glottochronology, where researchers [notably, @Swadesh1971] have proposed a list of 'universal concepts'--concepts that exist in all catalogued languages--in order to quantify the genealogical relatedness and dates of divergence of languages.
For example, the original Swadesh list contains 100 words, comprised of categories including common pronouns ("I", "you", "we"), animals ("man", "fish", "bird", "dog"), objects ("tree", "leaf", "sun", "mountain"), and verbs ("kill", "die", "see", "sleep").
An analogous Swadesh CDI would include all of the concepts that researchers have chosen to include on the vast majority of CDI:WS adaptations, and which have relatively similar difficulty across many languages.\footnote{Low variability in difficulty is important: consider for example 'hat', which is higher difficulty in Spanish ('sombrero'), which would lead to underestimation of language ability Spanish and overestimation in English.}

In particular, our contributions are 1) to fit IRT models to 28 CDI:WS datasets, 2) to identify 96 candidate "Swadesh CDI" items from a cross-linguistic comparison of concept difficulty and inclusion, and 3) to test how well this Swadesh CDI generalizes to a set of 8 additional low-data languages.
We end by making a concrete proposal for how this Swadesh CDI list could be used in creating future CDI adaptations, and by discussing the strengths and weaknesses of our approach. 

# Methods

## Item Response Theory

A variety of IRT models targeting different types of testing scenarios have been proposed [see @Baker2001 for an overview], but for the dichotomous responses that parents make for each item (word) regarding whether their child can produce that word, we will use the popular 2-parameter logistic (2PL) model that we have previously found is best justified for CDI data [see @Kachergis2022].

The 2PL model jointly estimates for each child $j$ a latent ability $\theta_j$ (here, language skill), and for each item $i$ two parameters: the item's difficulty $b_i$ and discrimination $a_i$, described below.
In the 2PL model, the probability of child $j$ producing a given item $i$ is 
 
 $$P_{i}(x_i = 1 | b_{i},a_{i},\theta_j ) = \frac{1}{1 + e^{-D a_{i}(\theta_j - b_i )}}$$

Thus, children with high latent ability ($\theta$) will be more likely to produce any given item than children with lower latent ability, and more difficult items will be produced by fewer children (at any given $\theta$) than easier items.
The discrimination ($a_i$) modifies the slope of the logistic (in the classic Rasch or 1PL model, the slope is always 1):
<!-- define D (review CATpaper explanation: ogive) --> 



## Datasets

```{r, load-wg-data, echo=F}
get_item_n_subject_counts <- function(models) {
  tab <- tibble()
  for(lang in names(coefs)) {
    nitems = models[[lang]]@Data$nitems
    N = models[[lang]]@Data$N
    tab = bind_rows(tab, tibble(Language = lang, items = nitems, N = N))
  }
  return(tab)
}

# WG production fits
load(here("data/multiling_2pl_WG_prod_fits.Rdata"))
wg_coefs = coefs
languages = names(coefs)
wg_tab <- get_item_n_subject_counts(models)
#sort(languages)

#load(here("data/xling_WG_abilities.Rdata"))
load(here("data/xling-WGprod-IRTparms.Rdata"))
# 24 languages, 9611 parameters
wg_parms <- xldf

```

```{r, load-ws-data, echo=F, results="asis"}
# WS production fits - can we stitch WG+WS for all of these?
load(here("data/multiling_2pl_WS_prod_fits.Rdata"))
ws_coefs = coefs

ws_tab <- get_item_n_subject_counts(models)

load(here("data/xling-WSprod-IRTparms.Rdata"))
ws_parms <- xldf # 23179

# WG langs that don't have WS: British Sign Language, Spanish (Chilean), American Sign Language, English (British)

it_tab <- ws_tab %>% rename(`WS items`=items, `WS N`=N) %>%
  #left_join(wg_tab %>% rename(`WG items`=items, `WG N`=N)) %>%
  arrange(desc(`WS N`))

low_data_langs <- it_tab %>% filter(`WS N`<200)

tab1 <- xtable::xtable(it_tab, digits=c(0), 
                       caption = "Number of CDI:WG and CDI:WS items and subjects (N) per language.")
print(tab1, type="latex", comment = F, table.placement = "H", include.rownames=FALSE)
# ToDo: italicize final eight rows (to be used as generalization test)
```


We report IRT analyses for twenty-six languages from Wordbank [@frank2017], comprising production data from CDI:WS vocabulary checklists.[^1]
Data from the first twenty-six rows of Table 1 (Norwegian through Dutch) will be used to select a pool of words with approximately equal cross-linguistic difficulty.
CDI:WS production data from an additional eight languages (Table 1: Greek (Cypriot) through Persian) had too few participants to be analyzed with IRT, but will be used to test how well the selected pool of generalize to new languages.

### Participants


<!-- The CDI:WG production dataset consists of the combined Wordbank production data for `r sum(wg_tab$N)` children aged 12-18 months on `r sum(wg_tab$items)` items across `r nrow(wg_tab)` forms. -->
The CDI:WS production dataset consists of the combined Wordbank production data for `r sum(ws_tab$N)` children aged 16-30 months on `r sum(ws_tab$items)` items across `r nrow(ws_tab)` forms.
Figure 1C and 1D shows children's production scores vs. age for the CDI:WG and CDI:WS datasets respectively.
Note that the socioeconomic distributions of these datasets are not matched. 
(See @frank2021 for a discussion of possible effects of socioeconomic status on vocabulary development.) 

[^1]: [http://wordbank.stanford.edu/contributors](http://wordbank.stanford.edu/contributors)


```{r, plot-production, echo=F, warning=F, eval=F, fig.width=6.5, fig.height=5.5, fig.cap="Children's CDI vocabulary plotted by age and sex in each dataset: (A) English comprehension, (B) Spanish comprehension, (C) English production, and (D) Spanish production. Note that we plot fitted quadratics showing extrapolated vocabulary sizes beyond the maximum CDI score, rather than an asymptotic logistic."}

en_prod <- d_demo_en %>% 
  mutate(sex = as.character(sex),
         sex = ifelse(sex=="Other", NA, sex)) %>%
  filter(!is.na(sex)) %>%
  ggplot(aes(x = age, y = production, group = sex, color = sex)) + 
  geom_jitter(alpha = .2) + theme_bw() + 
  stat_smooth(method = "glm", formula = y ~ 0 + x + I(x^2), size = 1) +
  xlab("Age (months)") + ylab("Words Produced") + xlim(11, 37) + ylim(0, 700) +
  ggtitle("English Production")

sp_prod <- ggplot(d_demo_sp, aes(x = age, y = production, group = sex, color = sex)) + 
  geom_jitter(alpha = .3) + theme_bw() + 
  xlab("Age (months)") + ylab("Words Produced") + xlim(11, 32) + ylim(0, 700) +
  stat_smooth(method = "glm", formula = y ~ 0 + x + I(x^2), size = 1) +
  ggtitle("Spanish Production")


ggarrange(en_prod, sp_prod,
          labels = c("A", "B"), 
          ncol=1, nrow=2, common.legend = T)
```


### Instruments

<!-- The 680-item vocabulary checklist of the English CDI:WS form is organized into 22 semantic categories (e.g., furniture, games and routines, people). -->
<!-- When a CDI:WG form was administered, caregivers were asked to indicate for each vocabulary item whether their child 1) understands that word ("comprehends") or 2) both understands and says ("produces") that word. 
Leaving the item blank indicates that the child neither comprehends nor produces that word. -->
When a CDI:WS forms was administered, caregivers were asked to indicate for each vocabulary item on the instrument whether or not their child can recognizably produce (say) the given word.

"Produces" responses were coded as 1 and all other responses were coded as 0.
Our datasets consist of a dichotomous-valued response matrix for each language, of size $N$ subjects $\times$ $W$ words.

# Results

All models, simulations, and other materials are available on OSF[^2].

[^2]: OSF repository: [https://osf.io/XXX/](https://osf.io/XXX/).



## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. 
We might expect this to recapitulate the historical relationship between languages, with more similar languages having more similar item difficulties (e.g., Quebecois and European French).

```{r xling-sim, fig.env = "figure*", fig.pos = "h", fig.width=7.5, fig.height=7.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Cross-linguistic similarity (Spearman correlation) of IRT item difficulty from the CDI:WS."}
xldf_lowd <- xldf %>% filter(is.element(language, low_data_langs$Language)) # 5464
xldf <- xldf %>% filter(!is.element(language, low_data_langs$Language)) # 17714

# parm diffs in low- vs. high-data langs
#t.test(xldf$d, xldf_lowd$d) # -.45 vs. -.02 (closer to prior of 0 in low-data langs)
#t.test(xldf$a1, xldf_lowd$a1) # higher discrim in high-data langs

languages = unique(xldf$language)

prod_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
prod_sims <- tibble()
colnames(prod_cors) = languages
rownames(prod_cors) = languages

for(l1 in languages) {
  for(l2 in languages) {
    tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
      select(uni_lemma, category, lexical_category, language, d) %>%
      group_by(uni_lemma, language) %>%
      slice(1) %>% 
      pivot_wider(names_from = language, values_from = d) %>%
      drop_na()
    prod_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
    prod_sims <- bind_rows(prod_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
  }
}

library(RColorBrewer)
library(gplots)
Colors = brewer.pal(11,"Spectral")
diag(prod_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)")
heatmap.2(prod_cors, col=Colors)

```


## Difficulty by CDI Category

Which categories are hardest? Easiest?
Which categories show the greatest variability? The least?

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=7.5, fig.height=9, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Mean difficulty of CDI words by semantic category. Bars represent bootstrapped 95\\% confidence intervals."}
# Russian has descriptive adjectives and adverbs
xldf[which(xldf$category=="descriptive_words (adjectives)"),]$category = "descriptive_words"
xldf[which(xldf$category=="outside_places"),]$category = "outside"


# remove categories that only exist in 1 or 2 languages:
prod_cat <- xldf %>% group_by(language, category) %>%
  filter(!is.na(d), !is.na(category),
         !is.element(category, c("final_particles", "directions", "numbers", "articles", "other",
                                 "descriptive_words (adverbs)", "states", "unknown",
                                 "verb_endings", "verb_modifiers",
                                 "classifiers", "locations_quantities_adverbs"))) %>%
  tidyboot::tidyboot_mean(d, na.rm=T)


# color=language
prod_cat %>% ggplot(aes(x=reorder(language, mean), y=mean)) + geom_point(alpha=.7) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
  facet_wrap(. ~ category) + coord_flip() + 
  theme_classic() + ylab("Mean item easiness") + xlab("Language")
#ggsave("xling_diff_by_category_WSprod.pdf", width=10, height=12)
```

### Identifying Swadesh CDI Candidates

```{r, echo=F, message=F, results='asis'}
pars <- xldf %>% filter(!is.na(uni_lemma), !is.na(d)) 

ul <- sort(table(pars$uni_lemma)) 

long_list = ul[which(ul>1)] # 1312
#short_list = ul[which(ul>5)] # 807
short_list = ul[which(ul>9)] # 656 uni-lemmas defined in 10+ languages
#short_list = ul[which(ul>12)] # 573 uni-lemmas defined in 10+ languages

```

```{r}
# problem: some languages have multiple items matching a single uni_lemma
# (e.g., Croatian has stric=uncle and ujak=uncle; Turkish has 3 "market"s )
prod_pars <-
  pars %>% arrange(desc(language), desc(uni_lemma), desc(a1)) %>% # get most discriminating uni_lemma per lang
  filter(is.element(uni_lemma, names(short_list))) %>%
  select(uni_lemma, category, lexical_category, language, d) %>%
  group_by(uni_lemma, language) %>%
  slice(1) %>% 
  pivot_wider(names_from = language, values_from = d)
```


CDI:WS forms have a median of 693 uni-lemmas defined (range: 553 (Czech) to 804 (Cantonese)), and there are a total of `r length(unique(xldf$uni_lemma))` uni-lemmas defined across the 26 languages.
Only `r nrow(na.omit(prod_pars))` uni-lemmas appear on all `r length(languages)` CDI:WS forms: too few to comprise a short form.
To expand the pool of items, we consider thresholds on both 1) the variability of an item's difficulty across languages (lower is better), and 2) the number of CDI:WS forms on which it appears (more is better).
Below we examine the standard deviation of uni-lemmas' cross-linguistic difficulty as a function of how many languages that uni-lemma is missing from.
For now we consider items with less than median variability in difficulty that are included on 10 or more of the 26 CDI:WS forms.

```{r, echo=F, include=F}
prod_pars$sd = apply(prod_pars[,4:ncol(prod_pars)], 1, sd, na.rm=T)
prod_pars$numNAs = apply(prod_pars[,4:ncol(prod_pars)], 1, function(x) { sum(is.na(x)) })

# median SD of the item difficulty
med_d = median(prod_pars$sd, na.rm=T) # 1.17
# SD of the SD
sd_d = sd(prod_pars$sd, na.rm=T) # .44

prod_pars %>% ggplot(aes(x=jitter(numNAs), y=sd, color=lexical_category)) + 
  geom_point(alpha=.7) + theme_classic() + 
  xlab("# of languages without uni-lemma") +
  ylab("SD of unilemma's cross-linguistic difficulty") +
  geom_hline(aes(yintercept=med_d - .5*sd_d), linetype="dashed") + 
  geom_vline(aes(xintercept=6.5), linetype="dashed")
```


```{r}
# look at different numNA thresholds...
gt_dat = tibble()
for(i in 1:26) {
  tmp <- prod_pars %>%
    filter(numNAs < i) 
  gt_dat <- gt_dat %>% 
    bind_rows(tibble(`# NAs` = i, 
                     `# Uni-lemmas` = nrow(tmp),
                     `Median(SD)` = median(tmp$sd, na.rm=T), 
                     `SD(d)` = sd(tmp$sd, na.rm=T)))
}

#View(gt_dat)

gt_dat %>% ggplot(aes(x=`# NAs`, y=`SD(d)`)) + 
  geom_point() + theme_classic()

good_prod <- prod_pars %>% 
  filter(numNAs < 16) %>%
  filter(sd < (med_d - .5*sd_d)) %>% 
  arrange(numNAs)
  #arrange(lexical_category, desc(sd))
```

Of these, a total of `r length(long_list)` uni-lemmas are included in more than one language, and only `r length(short_list)` uni-lemmas are included in 10 or more of the languages.
We will start by considering this more restricted list.

To evaluate how variable items are in their cross-linguistic difficulty, we calculate the standard deviation (SD) of each uni-lemma's difficulty.
The median SD is `r round(med_d, 2)` (SD=`r round(sd_d, 2)`), so we consider the items with SD less than half the median SD (i.e., SD < `r round(med_d - .5*sd_d, 2)`).
These `r nrow(good_prod)` candidate "Swadesh CDI" items are summarized by semantic category below (see OSF for full list).
52% of Swadesh CDI words are nouns, 21% are predicates, 22% are function words, and 5% are other.
This breakdown is comparable to the lexical category percentages on the 680-item English CDI:WS (46% nouns, 24% predicates, %15 function words, and 15%), minimally suggesting that this method of selecting candidate items is not biased by lexical category.
The candidate items, ultimately selected by lower variability, were also present on more forms than typical in the selection set: on average, each item appeared on `r 26-mean(good_prod$numNAs)` forms.

Comparing the IRT parameters of the Swadesh CDI words to the rest of the items showed that the candidate Swadesh items are significantly easier (mean Swadesh $d=0.03$, other items' mean $d=-0.51$, $t(2737)=12.74$, $p<.001$).
If the Swadesh list is too focused on early-learned items, this may result in ceiling effects for older children.
It may be prudent to consider expanding the Swadesh list to include some more difficult items.
The discrimination parameter (i.e., slope) of the Swadesh items did not significantly differ from the other items.

```{r, echo=F, results='asis'}
#sort(table(good_prod$category), decr=T)
#sort(table(good_prod$lexical_category), decr=T)
# c(50,20,5,21) / 96

# table(subset(xldf, language=="English (American)")$lexical_category) / 680
# function_words     nouns      other    predicates 
#    0.15          0.46      0.1470588      0.24

#kableExtra::kable(good_prod, digits=2)
#good_prod %>% DT::datatable() %>%
#  DT::formatRound(columns=4:24, digits=3)
tab2 <- good_prod %>% group_by(category) %>%
  summarise(n=n()) %>%
  arrange(desc(n))

tab2 <- xtable::xtable(tab2, digits=c(0), 
                       caption = "Number of proposed Swadesh CDI items by semantic category.")
print(tab2, type="latex", comment = F, table.placement = "H", include.rownames=FALSE)
```


```{r, swadesh-vs-non-swadesh-diff, echo=F}
xldf <- xldf %>% 
  mutate(SwadeshCDI=ifelse(is.element(uni_lemma, good_prod$uni_lemma), 1, 0))

tmp <- xldf %>% 
  group_by(SwadeshCDI) %>% 
  filter(!is.na(d)) %>%
  summarise(sd_d = sd(d), d = mean(d), 
            sd_a1 = sd(a1), a1 = mean(a1))
# mean easiness of Swadesh words: 0.03; mean easiness of other words: -0.51
# (mean of all: mean(xldf$d, na.rm=T) -0.45

#t.test(subset(xldf, SwadeshCDI==1)$a1, subset(xldf, SwadeshCDI==0)$a1) # n.s. diff in discrimination
#t.test(subset(xldf, SwadeshCDI==1)$d, subset(xldf, SwadeshCDI==0)$d)

gen_test_langs <- low_data_langs$Language
```

## Comparing Swadesh CDI to Full CDI:WS

How well do sumscores from the Swadesh CDI items correlate with full CDI:WS scores?
On average, for the 26 languages the IRT analysis was based on, the Swadesh CDI's sumscores were strongly related to the full CDI:WS scores (mean $r=0.990$; $min=0.976$, $max=0.996$).
However, these correlations were slightly but significantly lower than scores based on randomly-selected items (mean $r=0.993$, $min=0.990$, $max=0.996$, paired $t(25) = 5.67$, $p<.001$).
This is likely due to some ceiling effects for older children on the Swadesh CDI, since the randomly-selected items are likely somewhat easier on average than the Swadish items (see above results).

For the eight low-data languages, a similar comparison revealed that the Swadesh CDI's sumscores were again strongly related to the full CDI:WS scores (mean $r=0.978$; $min=0.959$, $max=0.992$).
As with the training set, however, the Swadesh list correlations were slightly but significantly lower than scores based on randomly-selected items (mean $r=0.985$; $min=0.972$, $max=0.992$; $t(7) = 3.22$, $p=.01$).


```{r generalization-test, echo=F, eval=F}
# use the good_prod words as a short CDI, and compare the correlation 
# of these words to a random selection (might be worse, due to being biased towards easy words?)

run_swadesh_comparisons <- function(xldf, languages) {
  xx <- tibble()
  for(lang in languages) {
    load(here(paste("data/WS/",lang,"_WS_data.Rdata", sep='')))
    swad_l <- subset(xldf, language==lang & is.element(uni_lemma, good_prod$uni_lemma)) # 
    swad_cor = cor(rowSums(d_prod, na.rm=T), rowSums(d_prod[,swad_l$item_id], na.rm=T))
    rand_inds = sample(1:ncol(d_prod), nrow(swad_l)) # N random words 
    rand_cor = cor(rowSums(d_prod, na.rm=T), rowSums(d_prod[,rand_inds], na.rm=T))
    xx <- xx %>% bind_rows(tibble(language = lang, `Swadesh r` = swad_cor, 
                                  `Rand r` = rand_cor, N = nrow(swad_l)))
  # d_demo, d_long, d_prod
  }
  return(xx)
}

xx <- run_swadesh_comparisons(xldf, languages)

#summary(xx$`Swadesh r`)
#   Min.  1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.9760  0.9886  0.9904  0.9895  0.9921  0.9955 
#summary(xx$`Rand r`)
#  Min.  1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.9898  0.9919  0.9936  0.9931  0.9944  0.9958 

gen_xx <- run_swadesh_comparisons(xldf_lowd, gen_test_langs)
#summary(gen_xx$`Rand r`)
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.9715  0.9842  0.9860  0.9852  0.9877  0.9920 

#summary(gen_xx$`Swadesh r`) 
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.9594  0.9746  0.9795  0.9781  0.9845  0.9924 
 
save(xx, gen_xx, file=here("data/Swadesh_comparisons.Rdata"))
```



```{r, include=F}
load(here("data/Swadesh_comparisons.Rdata"))

# are we any worse than random? slightly, but significantly...
#t.test(xx$`Swadesh r` - xx$`Rand r`)
# t(25) = -5.67, p<.001; diff=-.004
#t.test(gen_xx$`Swadesh r` - gen_xx$`Rand r`) 
# t(7) = -3.22, p=0.01;  diff=-.007

short_wsA <- read_csv(here("data/eng-ws-shortA.csv"))
short_wsB <- read_csv(here("data/eng-ws-shortB.csv"))

sort(intersect(short_wsA$word, good_prod$uni_lemma)) # 14
# "airplane" "broom"    "cat"      "dog"      "meow"     "milk"     "necklace"      
# "peas"     "school"   "shopping" "sky" "star"     "tonight"  "under"   
sort(intersect(short_wsB$word, good_prod$uni_lemma)) # 8
# "black"    "catch"    "dirty"    "hose"     
# "mailman"  "nose"     "tomorrow" "tongue" 

sort(short_wsA$word)
sort(good_prod$uni_lemma)
# remove: penis, vagina, 
```




ToDo: 
use average IRT parameter per item to calculate ability rather than sumscore?
propose a way of picking more difficult items? or maybe the value here is in finding the universal (easy) words, and it is up to expert native speakers to choose the more difficult (and idiosyncratic) words for each language.

If I had to find another way of getting the best cross-linguistic words, I would 1) run simulated CATs in all of the languages, and 2) pick the words that cropped up the most often across all languages. 

```{r swadesh-comparison, echo=F}
# https://en.wikipedia.org/wiki/Swadesh_list
swadesh100 = c()

# https://en.wikipedia.org/wiki/Automated_Similarity_Judgment_Program#Word_list
# ASJP subset of 40 Swadesh items that perform as well as full list
# categories: Body parts, Animals and plants, People, Nature, Verbs and adjectives, Numerals and pronouns
asjp = c("eye","ear","nose","tongue","tooth","hand","knee","blood","bone","breast","liver","skin",
         "louse", # "bug" ?
         "dog","fish (animal)","horn","tree","leaf",
         "person","name", # People; match "name" to "child's own name" / "babysitter's name" / "pet's name" ?
         "sun","star","water (not beverage)","fire","stone","path","mountain","night", # Nature
         "drink (action)","die","see","hear","come", # Verbs and adjectives
         "new","full","one","two","I","you","we")

#intersect(asjp, good_prod$uni_lemma) 
# "nose"   "tongue" "tooth"  "dog"    "star" 
```






# Discussion


# Acknowledgements

We would like to thank all of the contributors to Wordbank, from the researchers who created and adapted the CDIs to those who collected the data (as well as the participants), to those who have created and maintained Wordbank over the years. 

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
