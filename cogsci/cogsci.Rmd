---
title: "Measuring a Basic Developmental Vocabulary Across Many Languages"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf George Kachergis (kachergis@stanford.edu)} 
    \AND {\large \bf Virginia A. Marchman (marchman@stanford.edu)} 
    \AND {\large \bf Michael C. Frank (mcfrank@stanford.edu)} \\ Department of Psychology, 450 Jane Stanford Way \\ Stanford, CA 94305 USA}

abstract: >
    Early language skill is predictive of later life outcomes, and is thus of great interest to
    developmental psychologists and clinicians. The Communicative Development Inventories (CDIs),
    including a parent-reported inventory of early-learned vocabulary items, has proven to be
    a valid and reliable instrument for measuring children's early language skill. CDIs have been
    adapted to dozens of languages, and cross-linguistic comparisons thus far show both consistency 
    and variability in language acquisition trajectories. Here, we use item-response theory
    models to examine the psychometric properties of translation-equivalent concepts that 
    have been included on CDIs in several languages, with the goal of identifying a short list of
    concepts that are of approximately equal difficulty across the majority of the languages. 
    Using a list of XX items, we test how well this 
    
keywords: >
    early language learning; CDI; psychometrics; cross-linguistic comparison; Swadesh vocabulary;
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(xtable)
require(mirt)
require(tidyverse)
require(ggpubr)
require(tidyboot)
require(here)
```

# Introduction

Children's early language skill is predictive of educational outcomes, other developmental milestones, etc.

<!-- REWRITE INTRO -->
Assessing children's early language skill is important for researchers, clinicians and parents, as early language skill is predictive of educational outcomes years later.
The MacArthur-Bates Communicative Development Inventories [CDIs; @Fenson2007] are a set of parent report forms that offer a holistic assessment of children's productive and receptive language skills.
CDIs are low-cost to administer and produce reliable and valid estimates of early vocabulary and other aspects of early language [@fenson1994]. 
The CDIs offer more comprehensive data than a short interaction in the lab with a child [@Fenson2000], because they ask parents to report on vocabulary comprehension as well as production, and other milestones, such as communicative gesture use and use of word combinations. 
Vocabulary size is assessed via a checklist format, which allows caregivers to quickly scan and recognize words their child produces or understands, rather than relying on recall alone. 
Because of these properties, CDI forms have been adapted to dozens of languages. 
Data from CDIs are archived in a central repository [Wordbank; @frank2017], and insights from these data have been used to inform theories of early language learning [@frank2021]. 

Although CDIs measure a variety of other constructs related to early language, our focus here is on vocabulary assessment. 
Across languages, measures of vocabulary on the CDIs are very tightly correlated with other aspects of early language like gesture and grammatical competence [@bates1994; @frank2021]. 
These studies indicate that the language system looks to be "tightly woven" [@frank2021], in the sense that early vocabulary size serves as a good proxy measure of children's overall language skill. 


The CDI:WS form is comprised of 22 semantic categories representing common early-learned words, including nouns (subdivided into e.g., Body Parts, Toys, and Clothing), action words (e.g. verbs), descriptive words (e.g. adjectives), and closed-class words such as pronouns. 

<!--
In American English and Mexican Spanish (two of the original languages in which the CDIs were developed), there are two long-form CDI instruments that focus on different ages.
The 396-item vocabulary checklist on the CDI: Words & Gestures (CDI:WG) was designed for children ages 8--16 months and measures both comprehension and production.
The 680-item vocabulary checklist on the CDI: Words & Sentences (CDI:WS) targets children ages 16--30 months, and includes nearly all of the items from the CDI:WG form, but only measures production. 
All CDI forms include words from a range of semantic and syntactic categories. 
For example, 
-->

Although the CDIs have many advantages, one drawback is that it is difficult for researchers to adapt a CDI for a new language.

Due to these challenges, there have been a variety of efforts to create shortened versions of the CDI. 
The 100-item short-form CDIs [@Fenson2000; @Fenson2007] are derived from the 680-item CDI:WS form, with items selected based on difficulty and item-to-full score correlations, while also attempting to represent the diversity of semantic and linguistic categories.
While the scores of the short-form CDI:WS are highly correlated with scores on the full CDI:WS, there is evidence for a ceiling effect for children older than 27 or 28 months of age. 

The basis of CAT is item-response theory modeling [IRT; @embretson2013], a technique for the analysis of test data that allows the inference of both the abilities of test takers and the difficulty (and other information) of individual test questions along shared and standardized dimensions. 
CAT models use this item information -- typically extracted from a larger dataset collected via standard testing methods -- to select questions of the appropriate difficulty for a particular test-taker. 
An individual CAT includes a number of components, including the bank of possible items and their difficulties, as well as an algorithm that uses the responses received thus far to choose the next item to give to a test taker, and a rule for when to stop (e.g., after a fixed number of items or after a desired precision has been reached).  

Previous work has applied CAT and related techniques to CDI forms, leveraging the availability of large datasets from previous CDI studies where parents filled out the full forms [@Makransky2016;@mayor2019;@chai2020].
For example, @Makransky2016 used IRT models fit to normative data from the CDI:WS to develop CAT versions [@Fenson2007]. 
They conducted a simulation study comparing full scores on the CDI to different fixed-length CAT versions (with 5--400 items).
Scores from a CAT of only 50 items had a correlation of $r=0.95$ with the full CDI.
However, for the youngest age group (16--18 month-olds), the correlation with the full CDI was somewhat lower ($r=0.87$).


Our goal in the current work is to...
In particular, our contributions are:

We will first introduce the candidate Item Response Theory (IRT) models, fit them to the datasets, and assess which model is appropriate as the basis for the adaptive CDI. 
Next, we will conduct various CAT simulations to assess the effects of different design choices on test performance, and choose a set of preferred CAT parameters. 
Finally, we report results from a validation study.
We end by discussing the strengths and weaknesses of our approach. 

# Methods

## Item Response Theory Models

A variety of IRT models targeting different types of testing scenarios have been proposed [see @Baker2001 for an overview], but for the dichotomous responses that parents make for each item (word) regarding whether their child can produce that word, we will use the popular 2-parameter logistic (2PL) model that we have previously found is best justified for CDI data [see @Kachergis2022].

The 2PL model jointly estimates for each child $j$ a latent ability $\theta_j$ (here, language skill), and for each item $i$ two parameters: the item's difficulty $b_i$ and discrimination $a_i$, described below.
In the 2PL model, the probability of child $j$ producing a given item $i$ is 
 
 $$P_{i}(x_i = 1 | b_{i},a_{i},\theta_j ) = \frac{1}{1 + e^{-D a_{i}(\theta_j - b_i )}}$$

Thus, children with high latent ability ($\theta$) will be more likely to produce any given item than children with lower latent ability, and more difficult items will be produced by fewer children (at any given $\theta$) than easier items.
The discrimination ($a_i$) modifies the slope of the logistic (in the classic Rasch or 1PL model, the slope is always 1):
<!-- define D (review CATpaper explanation: ogive) --> 



## Datasets

```{r, load-wg-data, echo=F}
get_item_n_subject_counts <- function(models) {
  tab <- tibble()
  for(lang in names(coefs)) {
    nitems = models[[lang]]@Data$nitems
    N = models[[lang]]@Data$N
    tab = bind_rows(tab, tibble(Language = lang, items = nitems, N = N))
  }
  return(tab)
}

# WG production fits
load(here("data/multiling_2pl_WG_prod_fits.Rdata"))
wg_coefs = coefs
languages = names(coefs)
wg_tab <- get_item_n_subject_counts(models)
#sort(languages)

#load(here("data/xling_WG_abilities.Rdata"))
load(here("data/xling-WGprod-IRTparms.Rdata"))
# 24 languages, 9611 parameters
wg_parms <- xldf

```

```{r, load-ws-data, echo=F, results="asis"}
# WS production fits - can we stitch WG+WS for all of these?
load(here("data/multiling_2pl_WS_prod_fits.Rdata"))
ws_coefs = coefs

ws_tab <- get_item_n_subject_counts(models)

load(here("data/xling-WSprod-IRTparms.Rdata"))
ws_parms <- xldf # 23179

# WG langs that don't have WS: British Sign Language, Spanish (Chilean), American Sign Language, English (British)

it_tab <- ws_tab %>% rename(`WS items`=items, `WS N`=N) %>%
  left_join(wg_tab %>% rename(`WG items`=items, `WG N`=N)) %>%
  arrange(desc(`WS N`))

low_data_langs <- it_tab %>% filter(`WS N`<200)

tab1 <- xtable::xtable(it_tab, digits=c(0), 
                       caption = "Number of CDI:WG and CDI:WS items and subjects (N) per language.")
print(tab1, type="latex", comment = F, table.placement = "H", include.rownames=FALSE)
# ToDo: italicize final eight rows (to be used as generalization test)
```


We report IRT analyses for twenty-six languages from Wordbank [@frank2017], comprising production data from CDI:WS vocabulary checklists.
Data from the first twenty-six rows of Table 1 (Norwegian through Dutch) will be used to select a pool of words with approximately equal cross-linguistic difficulty.
CDI:WS production data from an additional eight languages (Table 1: Greek (Cypriot) through Persian) had too few participants to be analyzed with IRT, but will be used to test how well the selected pool of generalize to new languages.

### Participants

```{r}

```


<!-- The CDI:WG production dataset consists of the combined Wordbank production data for `r sum(wg_tab$N)` children aged 12-18 months on `r sum(wg_tab$items)` items across `r nrow(wg_tab)` forms. -->
The CDI:WS production dataset consists of the combined Wordbank production data for `r sum(ws_tab$N)` children aged 16-30 months on `r sum(ws_tab$items)` items across `r nrow(ws_tab)` forms.
Figure 1C and 1D shows children's production scores vs. age for the CDI:WG and CDI:WS datasets respectively.
Note that the socioeconomic distributions of these datasets are not matched. 
(See @frank2021 for a discussion of possible effects of socioeconomic status on vocabulary development.) 

[^1]: [http://wordbank.stanford.edu/contributors](http://wordbank.stanford.edu/contributors)
-->

```{r, plot-production, echo=F, warning=F, eval=F, fig.width=6.5, fig.height=5.5, fig.cap="Children's CDI vocabulary plotted by age and sex in each dataset: (A) English comprehension, (B) Spanish comprehension, (C) English production, and (D) Spanish production. Note that we plot fitted quadratics showing extrapolated vocabulary sizes beyond the maximum CDI score, rather than an asymptotic logistic."}

en_prod <- d_demo_en %>% 
  mutate(sex = as.character(sex),
         sex = ifelse(sex=="Other", NA, sex)) %>%
  filter(!is.na(sex)) %>%
  ggplot(aes(x = age, y = production, group = sex, color = sex)) + 
  geom_jitter(alpha = .2) + theme_bw() + 
  stat_smooth(method = "glm", formula = y ~ 0 + x + I(x^2), size = 1) +
  xlab("Age (months)") + ylab("Words Produced") + xlim(11, 37) + ylim(0, 700) +
  ggtitle("English Production")

sp_prod <- ggplot(d_demo_sp, aes(x = age, y = production, group = sex, color = sex)) + 
  geom_jitter(alpha = .3) + theme_bw() + 
  xlab("Age (months)") + ylab("Words Produced") + xlim(11, 32) + ylim(0, 700) +
  stat_smooth(method = "glm", formula = y ~ 0 + x + I(x^2), size = 1) +
  ggtitle("Spanish Production")


ggarrange(en_prod, sp_prod,
          labels = c("A", "B"), 
          ncol=1, nrow=2, common.legend = T)
```


### Instruments


The 680-item vocabulary checklist of the English CDI:WS form is organized into 22 semantic categories (e.g., furniture, games and routines, people). 
The Spanish CDI:WS vocabulary checklist consists of 680 words, organized into 23 semantic categories.
The English CDI:WG vocabulary checklist is comprised of XXX of the easier vocabulary items from the English CDI:WS, and the Spanish CDI:WG is a subset of XXX of the items from the Spanish CDI:WS. 

When a CDI:WG form was administered, caregivers were asked to indicate for each vocabulary item whether their child 1) understands that word ("comprehends") or 2) both understands and says ("produces") that word. 
Leaving the item blank indicates that the child neither comprehends nor produces that word.
When a CDI:WS forms was administered, caregivers were asked to indicate for each vocabulary item on the instrument whether or not their child can recognizably produce (say) the given word.

The current study solely investigates production, thus "produces" responses were coded as 1 and all other responses were coded as 0.
Our datasets consist of a dichotomous-valued response matrix for each language, of size $N$ subjects $\times$ $W$ words.

# Results

All models, simulations, and other materials are available on OSF[^2].

[^2]: OSF repository: [https://osf.io/XXX/](https://osf.io/XXX/).



## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. 
We might expect this to recapitulate the historical relationship between languages, with more similar languages having more similar item difficulties (e.g., Quebecois and European French).

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Cross-linguistic similarity (Spearman correlation) of IRT item difficulty from the CDI:WS."}
xldf_lowd <- xldf %>% filter(is.element(language, low_data_langs$Language)) # 5464
xldf <- xldf %>% filter(!is.element(language, low_data_langs$Language)) # 17714

# parm diffs in low- vs. high-data langs
t.test(xldf$d, xldf_lowd$d) # -.45 vs. -.02 (closer to prior of 0 in low-data langs)
t.test(xldf$a1, xldf_lowd$a1) # higher discrim in high-data langs

languages = unique(xldf$language)

prod_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
prod_sims <- tibble()
colnames(prod_cors) = languages
rownames(prod_cors) = languages

for(l1 in languages) {
  for(l2 in languages) {
    tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
      select(uni_lemma, category, lexical_category, language, d) %>%
      group_by(uni_lemma, language) %>%
      slice(1) %>% 
      pivot_wider(names_from = language, values_from = d) %>%
      drop_na()
    prod_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
    prod_sims <- bind_rows(prod_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
  }
}

library(RColorBrewer)
library(gplots)
Colors = brewer.pal(11,"Spectral")
diag(prod_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)")
heatmap.2(prod_cors, col=Colors)

```


## Difficulty by CDI Category

Which categories are hardest? Easiest?
Which categories show the greatest variability? The least?

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Mean difficulty of CDI words by semantic category. Bars represent bootstrapped 95% confidence intervals."}
# Russian has descriptive adjectives and adverbs
xldf[which(xldf$category=="descriptive_words (adjectives)"),]$category = "descriptive_words"
xldf[which(xldf$category=="outside_places"),]$category = "outside"


# remove categories that only exist in 1 or 2 languages:
prod_cat <- xldf %>% group_by(language, category) %>%
  filter(!is.na(d), !is.na(category),
         !is.element(category, c("final_particles", "directions", "numbers", "articles", "other",
                                 "descriptive_words (adverbs)", "states", "unknown",
                                 "verb_endings", "verb_modifiers",
                                 "classifiers", "locations_quantities_adverbs"))) %>%
  tidyboot::tidyboot_mean(d, na.rm=T)


# color=language
prod_cat %>% ggplot(aes(x=reorder(language, mean), y=mean)) + geom_point(alpha=.7) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
  facet_wrap(. ~ category) + coord_flip() + 
  theme_classic() + ylab("Mean item easiness") + xlab("Language")
#ggsave("xling_diff_by_category_WSprod.pdf", width=10, height=10)
```

### Candidate Items

Shown below are the total number of items per language that also have uni-lemmas.

```{r, echo=F, message=F}
pars <- xldf %>% filter(!is.na(uni_lemma), !is.na(d)) 

ul <- sort(table(pars$uni_lemma)) 

long_list = ul[which(ul>1)] # 1312
#short_list = ul[which(ul>5)] # 807
short_list = ul[which(ul>9)] # 656 uni-lemmas defined in 10+ languages
#short_list = ul[which(ul>12)] # 573 uni-lemmas defined in 10+ languages

tab <- sort(table(pars$language))
kableExtra::kable(tab, col.names=c("Language","Items"))
```

CDI:WS forms have a median of 693 uni-lemmas defined (range: 553 (Czech) to 804 (Cantonese)), and there are a total of `r length(unique(xldf$uni_lemma))` uni-lemmas defined across the 26 languages.
Only `r nrow(na.omit(prod_pars))` uni-lemmas appear on all `r length(languages)` CDI:WS forms: too few to comprise a short form.
To expand the pool of items, we consider thresholds on both 1) the variability of an item's difficulty across languages (lower is better), and 2) the number of CDI:WS forms on which it appears (more is better).
Below we examine the standard deviation of uni-lemmas' cross-linguistic difficulty as a function of how many languages that uni-lemma is missing from.
For now we consider items with less than median variability in difficulty that are included on 10 or more of the 26 CDI:WS forms.

```{r, echo=F}
# problem: some languages have multiple items matching a single uni_lemma
# (e.g., Croatian has stric=uncle and ujak=uncle; Turkish has 3 "market"s )
prod_pars <-
  pars %>% arrange(desc(language), desc(uni_lemma), desc(a1)) %>% # get most discriminating uni_lemma per lang
  filter(is.element(uni_lemma, names(short_list))) %>%
  select(uni_lemma, category, lexical_category, language, d) %>%
  group_by(uni_lemma, language) %>%
  slice(1) %>% 
  pivot_wider(names_from = language, values_from = d)

prod_pars$sd = apply(prod_pars[,4:ncol(prod_pars)], 1, sd, na.rm=T)
prod_pars$numNAs = apply(prod_pars[,4:ncol(prod_pars)], 1, function(x) { sum(is.na(x)) })

# median SD of the item difficulty
med_d = median(prod_pars$sd, na.rm=T) # 1.17
# SD of the SD
sd_d = sd(prod_pars$sd, na.rm=T) # .44

prod_pars %>% ggplot(aes(x=jitter(numNAs), y=sd, color=lexical_category)) + 
  geom_point(alpha=.7) + theme_classic() + 
  xlab("# of languages without uni-lemma") +
  ylab("SD of unilemma's cross-linguistic difficulty") +
  geom_hline(aes(yintercept=med_d - .5*sd_d), linetype="dashed") + 
  geom_vline(aes(xintercept=6.5), linetype="dashed")
```


```{r}
# look at different numNA thresholds...
gt_dat = tibble()
for(i in 1:26) {
  tmp <- prod_pars %>%
    filter(numNAs < i) 
  gt_dat <- gt_dat %>% 
    bind_rows(tibble(`# NAs` = i, 
                     `# Uni-lemmas` = nrow(tmp),
                     `Median(SD)` = median(tmp$sd, na.rm=T), 
                     `SD(d)` = sd(tmp$sd, na.rm=T)))
}

#View(gt_dat)

gt_dat %>% ggplot(aes(x=`# NAs`, y=`SD(d)`)) + 
  geom_point() + theme_classic()

good_prod <- prod_pars %>% 
  filter(numNAs < 16) %>%
  filter(sd < (med_d - .5*sd_d)) %>% 
  arrange(numNAs)
  #arrange(lexical_category, desc(sd))
```

Of these, a total of `r length(long_list)` uni-lemmas are included in more than one language, and only `r length(short_list)` uni-lemmas are included in 10 or more of the languages.
We will start by considering this more restricted list.

To evaluate how variable items are in their cross-linguistic difficulty, we calculate the standard deviation (SD) of each uni-lemma's difficulty.
The median SD is `r round(med_d, 2)` (SD=`r round(sd_d, 2)`), so we consider the items with SD less than half the median SD (i.e., SD < `r round(med_d - .5*sd_d, 2)`).
These `r nrow(good_prod)` candidate "Swadesh CDI" items are summarized by semantic category below (see OSF for full list).
52% of Swadesh CDI words are nouns, 21% are predicates, 22% are function words, and 5% are other.
This breakdown is comparable to the lexical category percentages on the 680-item English CDI:WS (46% nouns, 24% predicates, %15 function words, and 15%), minimally suggesting that this method of selecting candidate items is not biased by lexical category.
The candidate items, ultimately selected by lower variability, were also present on more forms than typical in the selection set: on average, each item appeared on `r 26-mean(good_prod$numNAs)` forms.

The Swadesh CDI words did significantly differ in difficulty, compared to the other 


```{r, echo=F, results='asis'}
#sort(table(good_prod$category), decr=T)
#sort(table(good_prod$lexical_category), decr=T)
# c(50,20,5,21) / 96

# table(subset(xldf, language=="English (American)")$lexical_category) / 680
# function_words     nouns      other    predicates 
#    0.15          0.46      0.1470588      0.24

#kableExtra::kable(good_prod, digits=2)
#good_prod %>% DT::datatable() %>%
#  DT::formatRound(columns=4:24, digits=3)
tab2 <- good_prod %>% group_by(category) %>%
  summarise(n=n()) %>%
  arrange(desc(n))

tab2 <- xtable::xtable(tab2, digits=c(0), 
                       caption = "Number of good cross-linguistic words by semantic category.")
print(tab2, type="latex", comment = F, table.placement = "H", include.rownames=FALSE)
```


```{r, swadesh-vs-non-swadesh-diff, echo=F}
xldf <- xldf %>% 
  mutate(SwadeshCDI=ifelse(is.element(uni_lemma, good_prod$uni_lemma), 1, 0))

tmp <- xldf %>% 
  group_by(SwadeshCDI) %>% 
  filter(!is.na(d)) %>%
  summarise(sd_d = sd(d), d = mean(d), 
            sd_a1 = sd(a1), a1 = mean(a1))
# mean easiness of Swadesh words: 0.03; mean easiness of other words: -0.51
# (mean of all: mean(xldf$d, na.rm=T) -0.45

#t.test(subset(xldf, SwadeshCDI==1)$a1, subset(xldf, SwadeshCDI==0)$a1) # n.s. diff in discrimination
t.test(subset(xldf, SwadeshCDI==1)$d, subset(xldf, SwadeshCDI==0)$d)
```


```{r generalization-test, echo=F}
gen_test_langs <- low_data_langs$Language

# use the good_prod words as a short CDI, and compare the correlation 
# of these words to a random selection (might be worse, due to being biased towards easy words?)

run_swadesh_comparisons <- function(xldf, languages) {
  xx <- tibble()
  for(lang in languages) {
    load(here(paste("data/WS/",lang,"_WS_data.Rdata", sep='')))
    swad_l <- subset(xldf, language==lang & is.element(uni_lemma, good_prod$uni_lemma)) # 
    swad_cor = cor(rowSums(d_prod, na.rm=T), rowSums(d_prod[,swad_l$item_id], na.rm=T))
    rand_inds = sample(1:ncol(d_prod), nrow(swad_l)) # N random words 
    rand_cor = cor(rowSums(d_prod, na.rm=T), rowSums(d_prod[,rand_inds], na.rm=T))
    xx <- xx %>% bind_rows(tibble(language = lang, `Swadesh r` = swad_cor, 
                                  `Rand r` = rand_cor, N = nrow(swad_l)))
  # d_demo, d_long, d_prod
  }
  return(xx)
}

xx <- run_swadesh_comparisons(xldf, languages)

mean(xx$`Rand r`) # .993
mean(xx$`Swadesh r`) # .990

gen_xx <- run_swadesh_comparisons(xldf_lowd, gen_test_langs)
mean(gen_xx$`Rand r`) # .985
mean(gen_xx$`Swadesh r`) # .978
```

compare to short form 

```{r swadesh-comparison, echo=F}
# https://en.wikipedia.org/wiki/Swadesh_list
swadesh100 = c()

# https://en.wikipedia.org/wiki/Automated_Similarity_Judgment_Program#Word_list
# ASJP subset of 40 Swadesh items that perform as well as full list
# categories: Body parts, Animals and plants, People, Nature, Verbs and adjectives, Numerals and pronouns
asjp = c("eye","ear","nose","tongue","tooth","hand","knee","blood","bone","breast","liver","skin",
         "louse", # "bug" ?
         "dog","fish (animal)","horn","tree","leaf",
         "person","name", # People; match "name" to "child's own name" / "babysitter's name" / "pet's name" ?
         "sun","star","water (not beverage)","fire","stone","path","mountain","night", # Nature
         "drink (action)","die","see","hear","come", # Verbs and adjectives
         "new","full","one","two","I","you","we")
```







# Discussion


# Acknowledgements

We would like to thank all of the contributors to Wordbank, from the researchers who created and adapted the CDIs to those who collected the data (as well as the participants), to those who have created and maintained Wordbank over the years. 

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
