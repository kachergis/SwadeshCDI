---
title: "Apophenia"
author: "George"
date: "`r Sys.Date()`"
output: html_document
---

```{r, include=F}
require(here)
require(tidyverse)
require(glue)
require(Hmisc)

source(here("cross-ling-comparison-helpers.R"))
```


```{r setup, eval=F, include=FALSE}
# for given lang, get graph of cor bw full WS and rand indices
get_random_cors <- function(lang, form="WS", nsamp=100) {
  message(glue("Processing {lang}\r"))
  load(here(paste("data/",form,"/",lang,"_",form,"_data.Rdata", sep='')))
  WS_tot = rowSums(d_prod, na.rm=T)
  steps = seq(25, 300, by=25)
  dat = tibble()
  for(step in steps) {
    for(i in 1:nsamp) {
      tmp = c()
      rand_idx = sample(1:ncol(d_prod), step)
      tmp = c(tmp, cor(WS_tot, rowSums(d_prod[,rand_idx], na.rm=T)))
    }
    dat = dat %>% 
      bind_rows(tibble(language = lang, 
                       N = step, 
                       mean_cor = mean(tmp)))
  }
  return(dat)
}


# now the same, but sample from English
eng_unis <- subset(xldf, language=="English (American)")
get_random_english_cors <- function(lang, form="WS", nsamp=100) {
  message(glue("Processing {lang}\r"))
  load(here(paste("data/",form,"/",lang,"_",form,"_data.Rdata", sep='')))
  # find all Eng unis that are in lang - will randomly draw from these
  poss_unis = subset(items, is.element(uni_lemma, eng_unis$uni_lemma))
  WS_tot = rowSums(d_prod, na.rm=T)
  steps = seq(25, 300, by=25)
  dat = tibble()
  for(step in steps) {
    for(i in 1:nsamp) {
      tmp = c()
      row_idx = sample(1:nrow(poss_unis), step)
      item_idx = poss_unis[row_idx,]$item_id
      tmp = c(tmp, cor(WS_tot, rowSums(d_prod[,item_idx], na.rm=T)))
    }
    dat = dat %>% 
      bind_rows(tibble(language = lang, 
                       N = step, 
                       mean_cor = mean(tmp)))
  }
  return(dat)
}


swad_list = swad_lists[[9]]
get_random_swadesh_cors <- function(lang, form="WS", nsamp=100) {
  message(glue("Processing {lang}\r"))
  load(here(paste("data/",form,"/",lang,"_",form,"_data.Rdata", sep='')))
  # find all Swad unis that are in lang - will randomly draw from these
  poss_unis = subset(items, is.element(uni_lemma, swad_list$uni_lemma))
  WS_tot = rowSums(d_prod, na.rm=T)
  steps = seq(25, nrow(poss_unis), by=25)
  dat = tibble()
  for(step in steps) {
    for(i in 1:nsamp) {
      tmp = c()
      row_idx = sample(1:nrow(poss_unis), step)
      item_idx = poss_unis[row_idx,]$item_id
      tmp = c(tmp, cor(WS_tot, rowSums(d_prod[,item_idx], na.rm=T)))
    }
    dat = dat %>% 
      bind_rows(tibble(language = lang, 
                       N = step, 
                       mean_cor = mean(tmp)))
  }
  return(dat)
}


get_all_random_cors <- function(languages) {
  dat <- tibble()
  for(lang in languages) {
    dat <- bind_rows(dat, get_random_cors(lang) %>% mutate(Random="Item"))
    dat <- bind_rows(dat, get_random_english_cors(lang) %>% mutate(Random="English"))
    dat <- bind_rows(dat, get_random_swadesh_cors(lang) %>% mutate(Random="Swadesh"))
  }
  return(dat)
}

dat <- get_all_random_cors(languages)
save(dat, file=here("data/apophenia.Rdata"))
```

Just pick N items, either from the target language's CDI:WS, or from English.

```{r, fig.width=8, fig.height=5}
load(here("data/apophenia.Rdata"))

dat %>% ggplot(aes(x=N, y=mean_cor, color=language)) + 
  facet_wrap(. ~ Random) + 
  geom_line() + theme_bw() 
```

```{r}
dat %>% group_by(N, Random) %>%
  summarise(mean_cor = mean(mean_cor)) %>%
  ggplot(aes(x=N, y=mean_cor, color=Random)) + 
  geom_line() + theme_bw() + ylim(.97, 1)
```

## Monte Carlo Construction of Swadesh Lists

Want to build a Swadesh list (SL) of a given length (N)?

  1) construct SL from N randomly-selected uni-lemmas (ToDo: try biasing this selection: weight by uni-lemma frequency, 1/variance of difficulty, discrimination...)
  2) evaluate correlation between SL and full CDI (per language, then average those correlations--shouldn't bias based on CDI admins)
  3) select a random item i to consider removing from SL, and a replacement uni-lemma 
  4) evaluate correlation of SL vs. SL with swapped item: if swap is better, accept with 95% probability.

Fun fact: there are $\sim10^{100}$ potential lists of length 50 (2000 choose 50).

```{r, echo=F}
# for each language, look for uni-lemmas in swad_list in xldf (may not find all of them!)
# and test correlation between swad_list subsample and full CDI.
# also test correlation of full CDI against many random samples of size length(swad_list)

# run once to resave d_prod data in 1 list (to save loading time)
resave_prod_data <- function(form="WS") {
  d_prodl = list()
  for(lang in languages) {
    load(here(paste("data/",form,"/",lang,"_",form,"_data.Rdata", sep='')))
    d_prodl[[lang]] = d_prod
  }
  save(d_prodl, file="data/WS_prod_per_lang.Rdata")
}

run_swadesh_comparisons <- function(xldf, languages, swad_list, form='WS') {
  xx <- tibble()
  for(lang in languages) {
    #load(here(paste("data/",form,"/",lang,"_",form,"_data.Rdata", sep='')))
    swad_l <- subset(xldf, language==lang & is.element(uni_lemma, swad_list)) 
    swad_cor = cor(rowSums(d_prodl[[lang]], na.rm=T), rowSums(d_prodl[[lang]][,swad_l$item_id], na.rm=T))
    
    xx <- xx %>% bind_rows(tibble(language = lang, sublist = "Swadesh", 
                                  run = NA, cor = swad_cor, N = nrow(swad_l)))
  }
  
  xx_sum <- xx %>% 
    group_by(language, sublist, N) %>%
    summarise(r = mean(cor)) %>%
    pivot_wider(names_from = sublist, values_from = r) %>%
    rename(`Swadesh r` = Swadesh)
  return(xx_sum)
}

# WS production fits
load(here("data/multiling_2pl_WS_prod_fits.Rdata"))
load(here("data/xling-WSprod-IRTparms.Rdata")) # 23179, 
#languages = names(coefs)

# combined d_prod data
load(here("data/WS_prod_per_lang.Rdata"))

xldf <- xldf %>% mutate(uni_lemma = ifelse(uni_lemma=="NA", NA, uni_lemma)) %>%
  mutate(d = -d) %>% # easiness -> difficulty
  filter(!is.na(d)) # removes 1 Slovak word with NA parameters (because all responses were 0)

xldf <- xldf %>% filter(!is.na(uni_lemma)) # 21824 out of 23020 have uni-lemmas defined 95%

unis <- xldf %>% filter(uni_lemma!="NA") %>%
  group_by(uni_lemma) %>% # category <- but many uni-lemmas are categorized differently across languages
  summarise(d_m=mean(d), a1_m=mean(a1), d_sd = sd(d), a1_sd = sd(a1), n=n())
# maybe should just take the highest-discrimination uni-lemma per form? (some forms have >1 of some unis)

ws_tab <- get_item_n_subject_counts(models)
languages = subset(ws_tab, N>=200)$Language
```



```{r, warning=F}
make_swadesh_list <- function(unis, n_items=100, iters=1000, cur_list=c()) {
  cors <- rep(NA, iters)
  if(length(cur_list)==0) {
    swad_inds = sample(1:nrow(unis), n_items, replace = F) # could weight by n, 1/d_sd...
  } else {
    swad_inds = cur_list
  }
  start_list = swad_inds
  xx_g <- run_swadesh_comparisons(xldf, languages, unis[swad_inds,]$uni_lemma, form='WS')
  for (i in 1:iters) {
    # swap in 1 new item
    drop_i = sample(1:n_items, 1)
    new_i = sample(setdiff(1:nrow(unis), swad_inds), 1) 
    swad_inds2 = c(swad_inds[-drop_i], new_i)
    xx_g2 <- run_swadesh_comparisons(xldf, languages, unis[swad_inds2,]$uni_lemma, form='WS') 
    l1r = mean(xx_g$`Swadesh r`) 
    l2r = mean(xx_g2$`Swadesh r`)
    # if l2 has better r than l1, use it (5% chance of keeping l1 even if worse)
    if(l1r < l2r && runif(1)<=.95) {
      swad_inds = swad_inds2
      xx_g = xx_g2
    }
    cors[i] = max(l1r, l2r)
  }
  return(list(start_list = start_list, 
              swad_inds=swad_inds, 
              cors=cors))
}
```

```{r, echo=F, eval=F}
result <- make_swadesh_list(unis, n_items=100, iters=1000)
result2 <- make_swadesh_list(unis, n_items=100, iters=1000)
result3 <- make_swadesh_list(unis, n_items=100, iters=1000)
result4 <- make_swadesh_list(unis, n_items=100, iters=1000)

# do more iterations:
result1_2 <- make_swadesh_list(unis, n_items=100, iters=9000, cur_list=result$swad_inds)
result2_2 <- make_swadesh_list(unis, n_items=100, iters=9000, cur_list=result2$swad_inds)
result3_2 <- make_swadesh_list(unis, n_items=100, iters=9000, cur_list=result3$swad_inds)
result4_2 <- make_swadesh_list(unis, n_items=100, iters=9000, cur_list=result4$swad_inds)

result1_3 <- make_swadesh_list(unis, n_items=100, iters=20000, cur_list=result1_2$swad_inds)
result2_3 <- make_swadesh_list(unis, n_items=100, iters=20000, cur_list=result2_2$swad_inds)
result3_3 <- make_swadesh_list(unis, n_items=100, iters=20000, cur_list=result3_2$swad_inds)
result4_3 <- make_swadesh_list(unis, n_items=100, iters=20000, cur_list=result4_2$swad_inds)

# are these converging at all?
length(intersect(result$swad_inds, result2$swad_inds)) # 1000: 19
length(intersect(result2$swad_inds, result3$swad_inds)) # 1000: 15
length(intersect(result$swad_inds, result3$swad_inds)) # 1000: 17
length(intersect(result$swad_inds, result4$swad_inds)) # 1000: 17

length(intersect(result$swad_inds, result2$swad_inds)) # 1000: 19
length(intersect(result2$swad_inds, result3$swad_inds)) # 1000: 15
length(intersect(result$swad_inds, result3$swad_inds)) # 1000: 17
length(intersect(result$swad_inds, result4$swad_inds)) # 1000: 17

# how many of the initial items remain? (after 10k iterations)
intersect(result$start_list, result1_2$swad_inds) # 9
intersect(result2$start_list, result2_2$swad_inds) # 10
intersect(result3$start_list, result3_2$swad_inds) # 5
intersect(result4$start_list, result4_2$swad_inds) # 7
# (after 30k iterations)
intersect(result$start_list, result1_3$swad_inds) # 8
intersect(result2$start_list, result2_3$swad_inds) # 9
intersect(result3$start_list, result3_3$swad_inds) # 7
intersect(result4$start_list, result4_3$swad_inds) # 5


save(result, result1_2, result1_3,
     result2, result2_2, result2_3,
     result3, result3_2, result3_3,
     result4, result4_2, result4_3,
     file=here("data/MH_Swadesh_lists.Rdata"))
```

Correlations on the four chains went from an initial (random) .986, .985, .984, and .981 to .996 for all four chains after 10k iterations (and still .9962 after 30k swaps). 
On average, only 8 of the initial 100 (random) items still remain after 10k swaps (7.25 after 30k).
Surprisingly, the chains started to converge: after 10k swaps, 11 uni-lemmas were on the final list of all 4 chains; 49 uni-lemmas were on the final lists of 3 or 4 chains, and 107 uni-lemmas were on the list of 2+ chains.
After 30k iterations, 21 items were on all four chains, 52 were on 3+ chains, and 110 were on 2+ chains.

Let's look at the properties of the 52 items on 3 or 4 chains after 30k iterations.

```{r, echo=F, warning=F}
load(here("data/MH_Swadesh_lists.Rdata"))

un1k <- sort(table(c(result$swad_inds, result2$swad_inds, 
                     result3$swad_inds, result4$swad_inds)), decr=T)
#length(which(un1k>2))
# after 1k, 10 items are on 3 of 4 lists
un10k <- sort(table(c(result1_2$swad_inds, result2_2$swad_inds, 
                      result3_2$swad_inds, result4_2$swad_inds)), decr=T)
un30k <- sort(table(c(result1_3$swad_inds, result2_3$swad_inds, 
                      result3_3$swad_inds, result4_3$swad_inds)), decr=T)
```

```{r eval=F, echo=F}
# @10k
length(which(un10k>3)) # 11 on all 4 chains
length(which(un10k>2)) # 49 on 3+ chains
length(which(un10k>1)) # 107 on 2+ chains

# @30k
length(which(un30k>3)) # 21 on all 4 chains
length(which(un30k>2)) # 52 on 3+ chains
length(which(un30k>1)) # 110 on 2+ chains
```

```{r, echo=F, warning=F}
sinds = as.numeric(names(un30k[which(un30k>2)]))

swad_unis <- unis[sinds,]$uni_lemma

unis <- unis %>% mutate(Swadesh = ifelse(is.element(uni_lemma, swad_unis), T, F))

unis %>% filter(n>1) %>%
  group_by(Swadesh) %>%
  summarise(d_m = mean(d_m), d_sd = mean(d_sd), 
            n = mean(n), a1_m = mean(a1_m))

#unis %>% 
#  ggplot(aes(x=a1_m, y=d_m, color=Swadesh)) +
#  geom_point()

p1 <- unis %>% 
  ggplot(aes(x=Swadesh, y=d_m)) +
  geom_violin() + theme_bw() + ylab("Difficulty") +
  stat_summary(fun.data=mean_sdl, geom="pointrange", color="black") +
  xlab("On 75%+ of Swadesh lists")

p2 <- unis %>% 
  ggplot(aes(x=Swadesh, y=d_sd)) +
  geom_violin() + theme_bw() + ylab("sd(Difficulty)") +
  stat_summary(fun.data=mean_sdl, geom="pointrange", color="black") +
  xlab("On 75%+ of Swadesh lists")

p3 <- unis %>% 
  ggplot(aes(x=Swadesh, y=a1_m)) +
  geom_violin() + theme_bw() + ylab("Discrimination") +
  stat_summary(fun.data=mean_sdl, geom="pointrange", color="black") +
  xlab("On 75%+ of Swadesh lists")

p4 <- unis %>% filter(n<50) %>%
  ggplot(aes(x=Swadesh, y=n)) +
  geom_violin() + theme_bw() + ylab("# of WS forms") +
  stat_summary(fun.data=mean_sdl, geom="pointrange", color="black") +
  xlab("On 75%+ of Swadesh lists")


ggpubr::ggarrange(p1, p2, p3, p4, nrow=2, ncol=2)
```

## Items on 4/4 chains

```{r}
alvins <- c("sweater","sick","knife","long","morning","animal","hear","jam","and",
            "motorcycle","camera","tear","brush (object)",
            "before","box","above","want","shoulder","skirt")

unis[as.numeric(names(un30k[which(un30k==4)])),]$uni_lemma
```

## Items on 3/4 chains

```{r}
unis[as.numeric(names(un30k[which(un30k==3)])),]$uni_lemma
```

