---
title: "Finding Equal Difficulty Cross-linguistic Items"
author: "George"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(mirt)
require(tidyverse)
load("data/multiling_2pl_WG_comp_fits.Rdata")

languages = c("Croatian","Danish","English (American)","Korean","Spanish (Mexican)",
              "Italian","Mandarin (Taiwanese)","French (French)", 
              "Latvian", "Hebrew", "Norwegian", "French (Quebecois)",
              "Slovak", "Spanish (European)", "Russian", "Turkish") 

join_lang_coefs <- function(languages, coefs) {
  xldf <- tibble()
  for(lang in languages) {
    load(paste("data/",lang,"_WG_data.Rdata", sep=''))
    ldat <- items %>% left_join(coefs[[lang]]) # either by "definition" or "item_id"
    xldf <- bind_rows(xldf, ldat)
  }
  return(xldf)
}

```

Our goal is to look at IRT parameters across a diverse set of languages and find a subset of uni-lemmas that are somewhat similar in their difficulty.
We'll start with 2PL fits to WG data (comprehension and production separately) for `r length(languages)` languages: `r languages`.
(Although 3 of these don't yet have uni-lemmas coded, but I'm working on that.)

## WG Comprehension

```{r, echo=F, message=F, eval=F}
coefs$Korean <- coefs$Korean %>% rename(item_id = definition)
coefs$`Spanish (Mexican)` <- coefs$`Spanish (Mexican)` %>% rename(item_id = definition)
coefs$`Spanish (European)` <- coefs$`Spanish (European)` %>% rename(item_id = definition)
coefs$Latvian <- coefs$Latvian %>% rename(item_id = definition)
coefs$Hebrew <- coefs$Hebrew %>% rename(item_id = definition)
coefs$Slovak <- coefs$Slovak %>% rename(item_id = definition)
coefs$`French (French)` <- coefs$`French (French)` %>% rename(item_id = definition)


xldf <- join_lang_coefs(languages, coefs) 

save(xldf, file="data/xling-WGcomp-IRTparms.Rdata")
```

```{r, echo=F}
load("data/xling-WGcomp-IRTparms.Rdata")
#table(xldf$language)
xldf %>% ggplot( aes(x=d, fill=language)) +
    geom_histogram(alpha=0.6, position = 'identity') +
    theme_classic() + xlab("Item Difficulty")
```


Mostly overlapping difficulty distributions, except for Danish, which is apparently quite difficult to learn (and this is using a N(0,3) prior on difficulty).

## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. 
We might expect this to recapitulate the historical relationship between languages, with more similar languages having more similar item difficulties (e.g., Quebecois and European French).

```{r, echo=F, fig.width=6.5, fig.height=6.5}
comp_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
comp_sims <- tibble()
colnames(comp_cors) = languages
rownames(comp_cors) = languages

for(l1 in languages) {
  for(l2 in languages) {
    tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
      select(uni_lemma, category, lexical_class, language, d) %>%
      group_by(uni_lemma, language) %>%
      slice(1) %>% 
      pivot_wider(names_from = language, values_from = d) %>%
      drop_na()
    comp_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
    comp_sims <- bind_rows(comp_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
  }
}

require(gplots)
library(RColorBrewer)
Colors = brewer.pal(11,"Spectral")
diag(comp_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)","Latvian","Spanish (European)")
heatmap.2(comp_cors[-c(7,9,14),-c(7,9,14)], col=Colors)
# subset(xldf, language=="Mandarin (Taiwanese)" & !is.na(uni_lemma))
# Mandarin (Taiwanese) is missing all uni_lemmas...we gotta fix that

```


## Difficulty by CDI Category

```{r, echo=F, fig.width=10, fig.height=10}
comp_cat <- xldf %>% group_by(language, category) %>%
  filter(!is.na(d), !is.na(category), 
         !is.element(category, c("articles", "connecting_words", "states", "other", "verb_endings", "prepositions", "outside_places", "descriptive_words (adjectives)",
                                 "descriptive_words (adverbs)", "helping_verbs"))) %>%
  tidyboot::tidyboot_mean(d, na.rm=T)

# color=language
comp_cat %>% ggplot(aes(x=reorder(language, mean), y=mean)) + geom_point(alpha=.7) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
  facet_wrap(. ~ category) + coord_flip() + 
  theme_classic() + ylab("Mean item difficulty") + xlab("Language")
#ggsave("xling_diff_by_category_WGcomp.pdf", width=10, height=10)
```

### Candidate Items

Shown below are the total number of items per language that also have uni-lemmas.

```{r, echo=F, message=F}
pars <- xldf %>% filter(!is.na(uni_lemma), !is.na(d)) 

ul <- sort(table(pars$uni_lemma))

long_list = ul[which(ul>1)] 
short_list = ul[which(ul>4)] 


# problem: some languages have multiple items matching a single uni_lemma
# (e.g., Croatian has stric=uncle and ujak=uncle; Turkish has 3 "market"s )
comp_pars <-
  pars %>% arrange(desc(language, uni_lemma, a1)) %>% # get most discriminating uni_lemma per lang
  filter(is.element(uni_lemma, names(short_list))) %>%
  select(uni_lemma, category, lexical_class, language, d) %>%
  group_by(uni_lemma, language) %>%
  slice(1) %>% 
  pivot_wider(names_from = language, values_from = d)

comp_pars$sd = apply(comp_pars[,4:11], 1, sd, na.rm=T)
comp_pars$numNAs = apply(comp_pars[,4:11], 1, function(x) { sum(is.na(x)) })

med_d = median(comp_pars$sd, na.rm=T) # 3.57
sd_d = sd(comp_pars$sd, na.rm=T)


good_items <- comp_pars %>% 
  filter(numNAs < 5) %>%
  filter(sd < (med_d - sd_d)) %>% 
  arrange(lexical_class, desc(sd))

tab <- table(pars$language)
kableExtra::kable(tab, col.names=c("Language","Items"))
```

Of these, a total of `r length(long_list)` uni-lemmas are included in more than one language, and only `r length(short_list)` uni-lemmas are included in 5 or more of the languages.
We will start by considering this more restricted list, but if there are not enough good candidates then we may consider making pairwise comparisons between each possible language pair (more flexible, but more complicated).
(There are only `r nrow(na.omit(comp_pars))` uni-lemmas used in all 9 languages.)

To evaluate how variable items are in their cross-linguistic difficulty, we calculate the standard deviation (SD) of each uni-lemma's difficulty.
The median SD is `r round(med_d, 2)` (SD=`r round(sd_d, 2)`), so we consider the `r nrow(good_items)` items with SD < `r round(med_d - sd_d, 2)`.
These items are shown below, sorted by lexical class and in order of increasing SD.

```{r, echo=F}
kableExtra::kable(good_items, digits=2)
```



## WG Production

Now we'll turn to production data.

```{r, eval=F, echo=F, message=F}
load("data/multiling_2pl_WG_prod_fits.Rdata")
# had to rename definition column for some languages (Korean & Spanish)
coefs$Korean <- coefs$Korean %>% rename(item_id = definition)
coefs$`Spanish (Mexican)` <- coefs$`Spanish (Mexican)` %>% rename(item_id = definition)
coefs$`Spanish (European)` <- coefs$`Spanish (European)` %>% rename(item_id = definition)
coefs$Latvian <- coefs$Latvian %>% rename(item_id = definition)
coefs$Hebrew <- coefs$Hebrew %>% rename(item_id = definition)
coefs$Slovak <- coefs$Slovak %>% rename(item_id = definition)
coefs$`French (French)` <- coefs$`French (French)` %>% rename(item_id = definition)


xldf <- join_lang_coefs(languages, coefs) 
save(xldf, file="data/xling-WGprod-IRTparms.Rdata")
```

```{r, echo=F}
load("data/xling-WGprod-IRTparms.Rdata")
#table(xldf$language)
xldf %>% ggplot( aes(x=d, fill=language)) +
    geom_histogram(alpha=0.6, position = 'identity') +
    theme_classic() + xlab("Item Difficulty")
```


## Cross-linguistic similarities

```{r, echo=F, fig.width=6.5, fig.height=6.5}
prod_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
prod_sims <- tibble()
colnames(prod_cors) = languages
rownames(prod_cors) = languages

for(l1 in languages) {
  for(l2 in languages) {
    tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
      select(uni_lemma, category, lexical_class, language, d) %>%
      group_by(uni_lemma, language) %>%
      slice(1) %>% 
      pivot_wider(names_from = language, values_from = d) %>%
      drop_na()
    prod_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
    prod_sims <- bind_rows(prod_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
  }
}

diag(prod_cors) = NA
heatmap.2(comp_cors[-c(7,9,14),-c(7,9,14)], col=Colors)
```


Mostly overlapping difficulty distributions (with a difficulty prior ~ N(0,3)).

## Difficulty by CDI Category

```{r, echo=F, fig.width=10, fig.height=10}
prod_cat <- xldf %>% group_by(language, category) %>%
  filter(!is.na(d), !is.na(category), 
         !is.element(category, c("articles", "connecting_words", "states", "other", "verb_endings", "prepositions", "outside_places", "descriptive_words (adjectives)",
                                 "descriptive_words (adverbs)", "helping_verbs"))) %>%
  tidyboot::tidyboot_mean(d, na.rm=T)

# color=language
prod_cat %>% ggplot(aes(x=reorder(language, mean), y=mean)) + geom_point(alpha=.7) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
  facet_wrap(. ~ category) + coord_flip() + 
  theme_classic() + ylab("Mean item difficulty") + xlab("Language")
#ggsave("xling_diff_by_category_WGprod.pdf", width=10, height=10)
```

### Candidate Items

Shown below are the total number of items per language that also have uni-lemmas.

```{r, echo=F, message=F}
pars <- xldf %>% filter(!is.na(uni_lemma), !is.na(d)) 

ul <- sort(table(pars$uni_lemma))

long_list = ul[which(ul>1)] 
short_list = ul[which(ul>4)] 

prod_pars <-
  pars %>% arrange(desc(language, uni_lemma, a1)) %>% # get most discriminating uni_lemma per lang
  filter(is.element(uni_lemma, names(short_list))) %>%
  select(uni_lemma, category, lexical_class, language, d) %>%
  group_by(uni_lemma, language) %>%
  slice(1) %>% 
  pivot_wider(names_from = language, values_from = d)

prod_pars$sd = apply(prod_pars[,4:11], 1, sd, na.rm=T)
prod_pars$numNAs = apply(prod_pars[,4:11], 1, function(x) { sum(is.na(x)) })


med_d = median(prod_pars$sd, na.rm=T) # 3.57
sd_d = sd(prod_pars$sd, na.rm=T)

good_items <- prod_pars %>% 
  filter(numNAs < 5) %>%
  filter(sd < 1.25) %>%  # 
  arrange(lexical_class, desc(sd))

tab <- table(pars$language)
kableExtra::kable(tab, col.names=c("Language","Items"))
```

Of these, a total of `r length(long_list)` uni-lemmas are included in more than one language, and only `r length(short_list)` uni-lemmas are included in 5 or more of the languages.
We will start by considering this more restricted list, but if there are not enough good candidates then we may consider making pairwise comparisons between each possible language pair (more flexible, but more complicated).
(There are only `r nrow(na.omit(prod_pars))` uni-lemmas used in all 9 languages.)

To evaluate how variable items are in their cross-linguistic difficulty, we calculate the standard deviation (SD) of each uni-lemma's difficulty.
The median SD is `r round(med_d, 2)` (SD=`r round(sd_d, 2)`), so we consider the `r nrow(good_items)` items with SD less than 1.25.
These items are shown below, sorted by lexical class and in order of increasing SD.

```{r, echo=F}
kableExtra::kable(good_items, digits=2)
```

