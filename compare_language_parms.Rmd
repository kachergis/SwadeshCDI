---
title: "Finding Equal Difficulty Cross-linguistic Items"
author: "George"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
require(mirt)
require(tidyverse)
require(ggpubr)
require(gplots)
library(RColorBrewer)

knitr::opts_chunk$set(echo = F)
```


```{r run-once, eval=FALSE}
# check convergence - could also print # subjects and words
check_models <- function(models) {
  langs <- names(models)
  for(lang in langs) {
    print(paste(lang, "converged:", models[[lang]]@OptimInfo$converged))
  }
}

# old version: join is messed up because some unicode characters got converted (in mirt?) e.g. 'Ä' became 'c'
join_lang_coefs <- function(languages, coefs, form="WG") {
  xldf <- tibble()
  for(lang in languages) {
    load(paste("data/",form,"/",lang,"_",form,"_data.Rdata", sep=''))
    ldat <- items %>% left_join(coefs[[lang]], 
                                by=c("item_id"="definition")) 
    # either by "definition" or "item_id"
    xldf <- bind_rows(xldf, ldat)
  }
  return(xldf)
}

load("data/multiling_2pl_WG_comp_fits.Rdata")

languages = names(coefs) #setdiff(names(coefs), c("Kigiriama"))

check_models(models) # all converged

xldf <- join_lang_coefs(languages, coefs)
# some unicode issue with the join: 
# table(subset(xldf, is.na(d))$language)
# 3 British Sign Language,
# 79 French (French) items, 1 Hebrew, 1 Slovak, 5 Kiswahili, 1 Dutch

save(xldf, file="data/xling-WGcomp-IRTparms.Rdata")


# WG prod
load("data/multiling_2pl_WG_prod_fits.Rdata")
check_models(models)
# not converged: Dutch, Spanish (Chilean), French (French), Kigiriama, Kiswahili


# WS prod
load("data/multiling_2pl_WS_prod_fits.Rdata")
check_models(models) # all converged

xldf <- join_lang_coefs(names(coefs), coefs, form="WS")
save(xldf, file="data/xling-WSprod-IRTparms.Rdata")


# WS prod with age
load("data/multiling_2pl_age_WS_prod_fits.Rdata")
check_models(models) # all converged

xldf <- join_lang_coefs(names(coefs), coefs, form="WS")
save(xldf, file="data/xling-age-WS-prod-IRTparms.Rdata")
```

```{r}
load("data/xling-WGcomp-IRTparms.Rdata")

# Korean coefs[[lang]] = 284, 297 items
sort(table(xldf$language))
```

Our goal is to look at IRT parameters across a diverse set of languages and find a subset of uni-lemmas that are somewhat similar in their difficulty.
We'll start with 2PL fits to WG data (comprehension and production separately) for `r length(unique(xldf$language))` languages: `r unique(xldf$language)`.

## WG Comprehension

```{r, echo=F, message=F, eval=F}
# Spanish (Mexican) has item_id column with definitions...
# others (e.g. Kigiriama) have definition column with item_ids (e.g., item_1)

# subset(xldf, is.na(d))
# only missing parameters for items that had all 0 or 1 responses in the data (85, most of em French)

```

```{r, echo=F}

#table(xldf$language)
xldf %>% ggplot( aes(x=d, fill=language)) +
    geom_histogram(alpha=0.6, position = 'identity') +
    theme_classic() + xlab("Item Easiness")
```


Mostly overlapping difficulty distributions (this is using a N(0,3) prior on difficulty).

## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. 
We might expect this to recapitulate the historical relationship between languages, with more similar languages having more similar item difficulties (e.g., Quebecois and European French).

```{r, echo=F, fig.width=8, fig.height=8}
comp_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
comp_sims <- tibble()
colnames(comp_cors) = languages
rownames(comp_cors) = languages

for(l1 in languages) {
  for(l2 in languages) {
    tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
      select(uni_lemma, category, lexical_category, language, d) %>%
      group_by(uni_lemma, language) %>%
      slice(1) %>% 
      pivot_wider(names_from = language, values_from = d) %>%
      drop_na()
    comp_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
    comp_sims <- bind_rows(comp_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
  }
}

Colors = brewer.pal(11,"Spectral")
diag(comp_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)")
heatmap.2(comp_cors, col=Colors)

```


## Difficulty by CDI Category

```{r, echo=F, fig.width=10, fig.height=10}
comp_cat <- xldf %>% group_by(language, category) %>%
  filter(!is.na(d), !is.na(category), 
         !is.element(category, c("articles", "connecting_words", "states", "other", "verb_endings", "prepositions", "outside_places", "descriptive_words (adjectives)",
                                 "descriptive_words (adverbs)", "helping_verbs"))) %>%
  tidyboot::tidyboot_mean(d, na.rm=T)

# color=language
comp_cat %>% ggplot(aes(x=reorder(language, mean), y=mean)) + geom_point(alpha=.7) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
  facet_wrap(. ~ category) + coord_flip() + 
  theme_classic() + ylab("Mean item easiness") + xlab("Language")
#ggsave("xling_diff_by_category_WGcomp.pdf", width=10, height=10)
```

### Candidate Items

Shown below are the total number of items per language that also have uni-lemmas.

```{r, echo=F, message=F}
pars <- xldf %>% filter(!is.na(uni_lemma), !is.na(d)) 

ul <- sort(table(pars$uni_lemma))

long_list = ul[which(ul>1)] # 723
short_list = ul[which(ul>5)] # 444

tab <- table(pars$language)
kableExtra::kable(tab, col.names=c("Language","Items"))
```

Below we examine the standard deviation of unilemmas' cross-linguistic difficulty as a function of how many languages that unilemma is missing from.
How should we choose thresholds for inclusion -- both on the variability of an item's difficulty, and on the number of languages in which it is included?
For now we consider items with less than median SD that are missing from no more than 6 languages (lower left region of plot).

```{r, echo=F}
# problem: some languages have multiple items matching a single uni_lemma
# (e.g., Croatian has stric=uncle and ujak=uncle; Turkish has 3 "market"s )
comp_pars <-
  pars %>% arrange(desc(language), desc(uni_lemma), desc(a1)) %>% # get most discriminating uni_lemma per lang
  filter(is.element(uni_lemma, names(short_list))) %>%
  select(uni_lemma, category, lexical_category, language, d) %>%
  group_by(uni_lemma, language) %>%
  slice(1) %>% 
  pivot_wider(names_from = language, values_from = d)

comp_pars$sd = apply(comp_pars[,4:ncol(comp_pars)], 1, sd, na.rm=T)
comp_pars$numNAs = apply(comp_pars[,4:ncol(comp_pars)], 1, function(x) { sum(is.na(x)) })

med_d = median(comp_pars$sd, na.rm=T) # 1.07
sd_d = sd(comp_pars$sd, na.rm=T) # .44

comp_pars %>% ggplot(aes(x=jitter(numNAs), y=sd, color=lexical_category)) + 
  geom_point(alpha=.7) + theme_classic() + 
  xlab("# of languages without uni-lemma") +
  ylab("SD of unilemma's cross-linguistic difficulty") +
  geom_hline(aes(yintercept=med_d - .5*sd_d), linetype="dashed") + 
  geom_vline(aes(xintercept=6.5), linetype="dashed")

good_comp <- comp_pars %>% 
  filter(numNAs < 7) %>%
  filter(sd < (med_d - .5*sd_d)) %>% 
  arrange(numNAs)
  #arrange(lexical_category, desc(sd))
```

Of these, a total of `r length(long_list)` uni-lemmas are included in more than one language, and only `r length(short_list)` uni-lemmas are included in 6 or more of the languages.
We will start by considering this more restricted list, but if there are not enough good candidates then we may consider making pairwise comparisons between each possible language pair (more flexible, but more complicated).
(There are only `r nrow(na.omit(comp_pars))` uni-lemmas used in all `r length(languages)` languages.)

To evaluate how variable items are in their cross-linguistic difficulty, we calculate the standard deviation (SD) of each uni-lemma's difficulty.
The median SD is `r round(med_d, 2)` (SD=`r round(sd_d, 2)`), so we consider the `r nrow(good_comp)` items with SD < `r round(med_d - .5*sd_d, 2)`.
These items are shown below, sorted by number of languages from which the unilemma is missing.

```{r, echo=F}
#kableExtra::kable(good_comp, digits=2)
good_comp %>% DT::datatable() %>%
  DT::formatRound(columns=4:24, digits=3)
```



## WG Production

Now we'll turn to production data.

```{r, eval=F, echo=F, message=F}
load("data/multiling_2pl_WG_prod_fits.Rdata")


xldf <- join_lang_coefs(names(coefs), coefs) 
sort(table(subset(xldf, is.na(d))$language)) # lots of missing parameters, but esp. French, Dutch, and Spanish (Peruvian)
save(xldf, file="data/xling-WGprod-IRTparms.Rdata")
```

```{r, echo=F}
load("data/xling-WGprod-IRTparms.Rdata")

# Virginia: "this", "that" vs. others - demonstratives are supposedly earlier learned
demons <- xldf %>% filter(!is.na(d)) %>%
  mutate(demonstrative = ifelse(uni_lemma=="this", "this", ifelse(uni_lemma=="that", "that", "non-demon"))) %>%
  filter(!is.na(demonstrative)) %>%
  group_by(language, demonstrative) %>%
  summarise(difficulty = -mean(d)) %>%
  group_by(demonstrative) %>%
  tidyboot::tidyboot_mean(difficulty)

#demons %>% ggplot(aes(x=demonstrative, y=mean)) + 
#  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper)) + geom_point() +
#  theme_classic() + ylab("Mean difficulty") + ggtitle("all words")

#table(xldf$language)
xldf %>% ggplot( aes(x=d, fill=language)) +
    geom_histogram(alpha=0.6, position = 'identity') +
    theme_classic() + xlab("Item Easiness")
```


## Cross-linguistic similarities

```{r, echo=F, fig.width=8, fig.height=8}
# remove/fix French (French)
languages = setdiff(names(coefs), c("French (French)", "Kigiriama"))

prod_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
prod_sims <- tibble()
colnames(prod_cors) = languages
rownames(prod_cors) = languages

for(l1 in languages) {
  for(l2 in languages) {
    tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
      select(uni_lemma, category, lexical_category, language, d) %>%
      group_by(uni_lemma, language) %>%
      slice(1) %>% 
      pivot_wider(names_from = language, values_from = d) %>%
      drop_na()
    prod_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
    prod_sims <- bind_rows(prod_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
  }
}

diag(prod_cors) = NA
heatmap.2(prod_cors, col=Colors)
```


Mostly overlapping difficulty distributions (with a difficulty prior ~ N(0,3)).

## Difficulty by CDI Category

```{r, echo=F, fig.width=10, fig.height=10}
prod_cat <- xldf %>% group_by(language, category) %>%
  filter(!is.na(d), !is.na(category), 
         !is.element(category, c("articles", "connecting_words", "states", "other", "verb_endings", "prepositions", "outside_places", "descriptive_words (adjectives)",
                                 "descriptive_words (adverbs)", "helping_verbs"))) %>%
  tidyboot::tidyboot_mean(d, na.rm=T)

# color=language
prod_cat %>% ggplot(aes(x=reorder(language, mean), y=mean)) + geom_point(alpha=.7) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
  facet_wrap(. ~ category) + coord_flip() + 
  theme_classic() + ylab("Mean item easiness") + xlab("Language")
#ggsave("xling_diff_by_category_WGprod.pdf", width=10, height=10)

#prod_cat %>% ggplot(aes(x=reorder(category, mean), y=mean)) + geom_point(alpha=.7) +
#  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), alpha=.7) +
#  facet_wrap(. ~ language) + coord_flip() + 
#  theme_classic() + ylab("Mean item easiness") + xlab("Category")
```

### Candidate Items

Shown below are the total number of items per language that also have uni-lemmas.

```{r, echo=F, message=F}
pars <- xldf %>% filter(!is.na(uni_lemma), !is.na(d)) 

ul <- sort(table(pars$uni_lemma))

long_list = ul[which(ul>1)] # 701
short_list = ul[which(ul>5)] # 428

tab <- table(pars$language)
kableExtra::kable(tab, col.names=c("Language","Items"))
```

Below we examine the standard deviation of unilemmas' cross-linguistic difficulty as a function of how many languages that unilemma is missing from.
What thresholds to use for inclusion?
For now we consider items with less than median SD that are missing from no more than 6 languages (lower left region of plot).

```{r, echo=F}
prod_pars <-
  pars %>% arrange(desc(language), desc(uni_lemma), desc(a1)) %>% # get most discriminating uni_lemma per lang
  filter(is.element(uni_lemma, names(short_list))) %>%
  select(uni_lemma, category, lexical_category, language, d) %>%
  group_by(uni_lemma, language) %>%
  slice(1) %>% 
  pivot_wider(names_from = language, values_from = d)

prod_pars$sd = apply(prod_pars[,4:19], 1, sd, na.rm=T)
prod_pars$numNAs = apply(prod_pars[,4:19], 1, function(x) { sum(is.na(x)) })


med_d = median(prod_pars$sd, na.rm=T) # 2.25
sd_d = sd(prod_pars$sd, na.rm=T) # .81

prod_pars %>% ggplot(aes(x=jitter(numNAs), y=sd, color=lexical_category)) + 
  geom_point(alpha=.7) + theme_classic() + 
  xlab("# of languages without uni-lemma") +
  ylab("SD of unilemma's cross-linguistic difficulty") +
  geom_hline(aes(yintercept=med_d - .5*sd_d), linetype="dashed") + 
  geom_vline(aes(xintercept=6.5), linetype="dashed")

good_prod <- prod_pars %>% 
  filter(numNAs < 7) %>%
  filter(sd < (med_d - .5*sd_d)) %>%  
  arrange(numNAs)
  #arrange(lexical_category, desc(sd))

save(good_prod, good_comp, file="data/good_crosslinguistic_items.RData")
```

Of these, a total of `r length(long_list)` uni-lemmas are included in more than one language, and only `r length(short_list)` uni-lemmas are included in 6 or more of the languages.
We will start by considering this more restricted list, but if there are not enough good candidates then we may consider making pairwise comparisons between each possible language pair (more flexible, but more complicated).
(There are only `r nrow(na.omit(prod_pars))` uni-lemmas used in all `r length(languages)` languages.)

To evaluate how variable items are in their cross-linguistic difficulty, we calculate the standard deviation (SD) of each uni-lemma's difficulty.
The median SD is `r round(med_d, 2)` (SD=`r round(sd_d, 2)`), so we consider the `r nrow(good_prod)` items with SD less than `r round(med_d - .5*sd_d,2)`.
These items are shown below, sorted by number of languages from which the unilemma is missing.

```{r, echo=F}
#kableExtra::kable(good_prod, digits=2)
good_prod %>% DT::datatable() %>%
  DT::formatRound(columns=4:24, digits=3)
```

## Overview of Cross-linguistic Comprehension and Production Difficulties by Category

```{r, echo=F, fig.width=12, fig.height=9}
posish = position_dodge2(.5)
p1 <- comp_cat %>% ggplot(aes(x=reorder(category, mean), y=mean, color=language)) + geom_point(alpha=.7, position=posish) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), position=posish, alpha=.7) +
  coord_flip() + 
  theme_classic() + ylab("Mean item easiness") + xlab("Category")
#ggsave("xling_diff_by_category_WGcomp_color.pdf", width=8, height=9)

p2 <- prod_cat %>% ggplot(aes(x=reorder(category, mean), y=mean, color=language)) + geom_point(alpha=.7, position=posish) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), position=posish, alpha=.7) +
  coord_flip() + 
  theme_classic() + ylab("Mean item easiness") + xlab("Category")
#ggsave("xling_diff_by_category_WGprod_color.pdf", width=8, height=9)

ggarrange(p1, p2, common.legend = T)
```


## Next steps

`r length(intersect(good_comp$uni_lemma, good_prod$uni_lemma))` of the uni-lemmas are on both the good cross-linguistic comprehension and production lists.
Is this enough items, or do we want to relax the criteria for inclusion?
How does the difficulty of these "good" items compare to the overall item difficulties? (Are they systematically easier? If so, the list may not work well for a short form CDI since it will overestimate vocabulary size. Should plot sd(difficulty) vs. mean(difficulty).)
The next step is to do real-data simulations for each language using these items, and see how well we recover full CDI scores / ability. 
If this doesn't work well, we may consider constructing pairwise language lists.