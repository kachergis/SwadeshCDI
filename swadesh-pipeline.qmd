---
title: "Swadesh CDI pipeline"
format: html
---

```{r}
library(wordbankr)
library(tidyverse)
library(glue)
library(mirt)
library(RColorBrewer)
require(gplots)
walk(list.files("scripts", pattern = "*.R$", full.names = TRUE), source)
```

# Data fetching and stitching
Get new form definitions with unified items
```{r}
languages <- list.files("data/new_items") |> str_sub(end = -5)
pronouns <- read_csv("data/pronouns.csv") |> 
  mutate(uid = glue("{form}_{itemID}"))

rep_items <- list()

# Validate to ensure no repeated items
for (language in languages) {
  ni <- get_new_items(language, pronouns)
  forms <- ni$forms
  new_items <- ni$new_items
  rep_ids <- new_items |> 
    select(category, definition) |> 
    duplicated()
  repeated <- new_items[rep_ids,]
  
  if (nrow(repeated) > 0) {
    repeated <- repeated |> 
      mutate(language = language)
    rep_items <- c(rep_items, list(repeated))
  }
}
```

Stitch data together and save outputs
```{r, eval=F}
for (language in languages) {
  ni <- get_new_items(language, pronouns)
  # Finnish WG/WGShort not yet imported
  if (language == "Finnish") ni$forms <- c("WS", "WSShort")
  df <- make_data(language, ni$forms, ni$new_items)
  
  output <- list(all_demo = df$all_demo,
                 items = ni$new_items,
                 all_long = df$all_long,
                 all_prod = df$all_prod)
  
  saveRDS(output, glue("data/all_forms/{language}_data.rds"))
}
```

# IRT modelling and parameter extraction
Run 2PL models
```{r}
languages <- list.files("data/all_forms") |> str_sub(end = -10)
```

```{r eval=F}
completed <- list.files("data/prod_models") |> str_sub(end = -28)

mirtCluster()
for (language in setdiff(languages, completed)) {
  run_2PL_model(language)
}
```

Collapse cross-linguistic item parameters
```{r eval=F}
xldf <- list()
full_fscores <- list()
for (language in languages) {
  lang_data <- readRDS(glue("data/all_forms/{language}_data.rds"))
  fitted <- readRDS(glue("data/prod_models/{language}_2PL_allforms_prod_fits.rds"))
  lang_fscores <- data.frame(fscores(fitted$model, full.scores = F)) # default method is EAP; prefer MAP or ML?
  full_fscores[[language]] <- tibble(full_theta = lang_fscores$G,
                                     full_sumscore = rowSums(lang_fscores |> select(-G, -SE_G), na.rm=T))
  # could also pull age from lang_data$all_demo
  df <- fitted$coefs |> 
    rename("uid" = "definition") |> 
    left_join(lang_data$items |> 
                select(uid, category, definition, gloss, uni_lemma),
              by = "uid") |> 
    mutate(language = language)
  xldf <- c(xldf, list(df))
}
xldf <- bind_rows(xldf)
saveRDS(xldf, "data/xldf_prod_allforms.rds")
saveRDS(full_fscores, "data/full_fscores_allforms.rds")
# xx <- bind_rows(full_fscores)
# plot(xx$full_theta, xx$full_sumscore) # cor = .71
```

```{r}
xldf <- readRDS("data/xldf_prod_allforms.rds")
```

Clean xldf
```{r}
xldf_clean <- xldf |> 
  filter(!is.na(uni_lemma), !is.na(d)) |> 
  mutate(category = case_when(
    category == "descriptive_words (adjectives)" ~ "descriptive_words",
    category == "outside_places" ~ "outside",
    .default = category))

prod_pars <- xldf_clean |> 
  arrange(language, uni_lemma, desc(a1)) |> # get most discriminating uni_lemma per lang
  select(uni_lemma, language, uid, category, language, d) |>
  group_by(uni_lemma, language) |>
  slice(1) |> 
  ungroup()

gen_langs <- c("Finnish",
               "Kigiriama",
               "American Sign Language",
               "Greek (Cypriot)",
               "Spanish (Peruvian)",
               "British Sign Language",
               "Persian",
               "Kiswahili",
               "English (Irish)",
               "Irish",
               "Spanish (Chilean)")

train_langs <- setdiff(languages, gen_langs)
```

# Cross-validation
```{r}
S_LEN = 100 # Swadesh list length
N_RAND = 100 # number of random sublists to compare to

cv_res <- lapply(train_langs, \(lang) {
  message(glue("Calculating for {lang}..."))
  
  prod_sum <- prod_pars |> 
    filter(language %in% train_langs,
           language != lang) |> 
    group_by(uni_lemma) |> 
    summarise(num_langs = n(),
              mean_d = mean(d, na.rm = TRUE),
              sd_d = sd(d, na.rm = TRUE))
  prod_test <- prod_pars |> 
    filter(language == lang)
  
  # Swadesh 
  prod_cors <- sapply(2:(length(train_langs)-1), \(k) {
    sublist <- make_swadesh_sublist(prod_sum, S_LEN, k)
    get_difficulty_cor(sublist, prod_test)
  }) |> t() |> 
    `colnames<-`(c("num_overlap", "difficulty_cor")) |> 
    as_tibble() |> 
    mutate(run = NA,
           k = 2:(length(train_langs)-1),
           language = lang,
           sublist = "Swadesh")
  
  # random
  rand_cors <- lapply(2:(length(train_langs)-1), \(k) {
    rand_cors <- sapply(1:N_RAND, \(comp) {
      sublist <- make_random_sublist(prod_sum, S_LEN, k)
      get_difficulty_cor(sublist, prod_test)
    }) |> t() |> 
      `colnames<-`(c("num_overlap", "difficulty_cor")) |> 
      as_tibble() |> 
      mutate(run = 1:N_RAND,
             k = k)
  }) |> 
    bind_rows() |> 
    mutate(language = lang,
           sublist = "Random")
  
  bind_rows(prod_cors, rand_cors)
}) |> bind_rows()

cv_res_sum <- cv_res |> 
  group_by(k, language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            difficulty_cor = mean(difficulty_cor)) |> 
  mutate(difficulty_cor_t = atanh(difficulty_cor)) # Fisher transform
```

```{r}
ggplot(cv_res_sum,
       aes(x = k, y = difficulty_cor, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(y = "Difficulty correlation") +
  theme(legend.position = "bottom") + theme_classic()
```

```{r}
ggplot(cv_res_sum,
       aes(x = k, y = num_overlap, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(y = "Overlap") +
  theme_classic() + 
  theme(legend.position = "bottom") 
```
CV results show that $k=20$ is the optimal value; we use this to construct the final list for generalization testing.

# Generalization test
```{r}
all_prod <- readRDS("data/allforms_prod_per_lang.rds")
```

```{r}
K = 20

prod_sum <- prod_pars |> 
  filter(language %in% train_langs) |> 
  group_by(uni_lemma) |> 
  summarise(num_langs = n(),
            mean_d = mean(d, na.rm = TRUE),
            sd_d = sd(d, na.rm = TRUE))

# Swadesh 
swadesh_sublist <- make_swadesh_sublist(prod_sum, S_LEN, K)
prod_cors <- sapply(gen_langs, \(lang) {
  get_sumscore_cor(swadesh_sublist, xldf, all_prod, lang)
}) |> t() |>
  `colnames<-`(c("num_overlap", "sumscore_cor")) |> 
  as_tibble(rownames = "language") |> 
  mutate(sublist = "Swadesh")

# random
rand_cors <- lapply(gen_langs, \(lang) {
  rand_cors <- sapply(1:N_RAND, \(comp) {
    sublist <- make_random_sublist(prod_sum, S_LEN, K)
    get_sumscore_cor(sublist, xldf, all_prod, lang)
  }) |> t() |> 
    `colnames<-`(c("num_overlap", "sumscore_cor")) |> 
    as_tibble() |> 
    mutate(run = 1:N_RAND,
           language = lang)
}) |> 
  bind_rows() |> 
  mutate(sublist = "Random")

gen_res <- bind_rows(prod_cors, rand_cors)

gen_res_sum <- gen_res |> 
  group_by(language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            sumscore_cor = mean(sumscore_cor)) |> 
  mutate(sumscore_cor_t = atanh(sumscore_cor)) # Fisher transform
```

```{r}
ggplot(gen_res_sum,
       aes(x = language, y = sumscore_cor, fill = sublist)) +
  geom_col(position = "dodge") +
  labs(y = "Sumscore correlation") +
  theme_classic() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) 
```

```{r}
ggplot(gen_res_sum,
       aes(x = language, y = num_overlap, fill = sublist)) +
  geom_col(position = "dodge") +
  labs(y = "Overlap size") +
  theme_classic() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```


### Compare Swadesh thetas to full CDI thetas/sumscores (and to random sumscores)
```{r, eval=F}
full_fscores <- readRDS("data/full_fscores_allforms.rds")

# either do this in cross-validation (show that thetas from swadesh lists are better for training languages)
# ..may not make sense for gen languages because those models are trained on little data (may not be stable parms)

# sublist vs sumscore may be similar, but backtracked thetas should be more sensitive

# swadesh_sublist$uni_lemma -> xldf$uid

# we actually want the average difficulty for Swadesh items, and we will use this to define a model to get predicted fscores from 
#swadesh_sublist$mean_d

#  https://groups.google.com/g/mirt-package/c/TLv1JFq2tCg
  
theta_comps <- tibble()
for (lang in languages) {
  lang_data <- readRDS(glue("data/all_forms/{lang}_data.rds"))
  fitted <- readRDS(glue("data/prod_models/{lang}_2PL_allforms_prod_fits.rds"))
  # get UIDs of non-Swadesh items
  non_swad_item_ids <- xldf %>% filter(language==lang, !is.element(uni_lemma, swadesh_sublist$uni_lemma)) %>% 
    pull(uid)
  #non_swad_item_ids <- setdiff(colnames(fitted$model@Data$data), swad_item_ids)
  # mask (NA) the responses to non-Swadesh items
  masked_resps <- fitted$model@Data$data
  masked_resps[,non_swad_item_ids] = NA
  full_sumscores <- rowSums(fitted$model@Data$data, na.rm=T)
  # lang_data$all_prod # these data still have 0-producing children -- should we infer thetas for them?
  
  full_fscores_lang <- fscores(fitted$model, response.pattern=fitted$model@Data$data, method="MAP")[,1] 
  
  # this uses the trained model for this lang -- but we want to use average Swadesh item difficulties (from training langs)
  #swad_fscores <- fscores(fitted$model, response.pattern=masked_resps, method="MAP")[,1] 
  # default method is EAP; prefer MAP or ML?
  
  # this lang Swadesh uid and uni_lemmas
  lang_swad_items <- xldf_clean |> filter(language==lang, is.element(uni_lemma, swadesh_sublist$uni_lemma))
  
  # original tis lang IRT parms
  modpars <- mod2values(fitted$model) %>% filter(is.element(item, lang_swad_items$uid))
    #mutate(value = ifelse(name=='a1', 1, value)) 
  
  new_vals <- modpars %>% select(item, name, value) %>%
    pivot_wider(names_from=name, values_from = value) %>%
    mutate(a1 = 1) %>% select(-d) %>% 
    left_join(lang_swad_items %>% select(uid, uni_lemma), by=c("item"="uid")) %>% # get uni_lemma
    left_join(swadesh_sublist %>% select(uni_lemma, mean_d)) %>% # get mean Swadesh difficulty
    rename(d = mean_d) %>%
    pivot_longer(cols = c(a1,d,g,u)) %>% 
    select(-uni_lemma)
  
  new_modpars <- modpars %>% select(-value) %>% left_join(new_vals) %>% 
    relocate(value, .after=parnum) %>%
    mutate(est = FALSE)
  
  # this works, but we need to 1) remove (or NA?) non-Swadesh columns, and 2) remove (or NA?) non-Swadesh parameters
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=mod2values(fitted$model))
  
  # Error: Rows in supplied and starting value data.frame objects do not match. Were the
  #           data or itemtype input arguments modified?
  
  swad_mod <- mirt(masked_resps[,unique(new_vals$item)], 1, pars=mod2values(fitted$model))
  # Error: Rows in supplied and starting value data.frame objects do not match. Were the
  #           data or itemtype input arguments modified?
  # parnum has a parameter index that is related to the number of participants (rows) in the data...
  # and maybe based on alphabetical order of participant and item names??
  # modpars$parnum # 1-116; 125-128... skips around!
  # can we just renumber parnum ??
  #new_modpars2 <- new_modpars %>% mutate(parnum = 1:nrow(new_modpars)) # did not work
  
  tmp <- na.omit(data.frame(cbind(full_fscores_lang, swad_fscores, full_sumscores)))
  full_theta_vs_swad_theta = cor(tmp$full_fscores_lang, tmp$swad_fscores)
  full_sum_vs_swad_theta = cor(tmp$full_sumscores, tmp$swad_fscores)
  full_sum_vs_full_theta = cor(tmp$full_sumscores, tmp$full_fscores_lang)
  
  # random theta cors
  rand_theta_cors <- sapply(1:N_RAND, \(comp) {
      sublist <- make_random_sublist(prod_sum, S_LEN, K) # use optimal K (20)
      rand_ids <- xldf %>% filter(language==lang, is.element(uni_lemma, sublist$uni_lemma)) %>% 
        pull(uid)
      
      # sumscores for random sublist:
      rand_sumscores <- rowSums(fitted$model@Data$data[,rand_ids], na.rm=T)
      
      # fscores for random sublist:
      unselected_item_ids <- xldf %>% filter(language==lang, !is.element(uni_lemma, sublist$uni_lemma)) %>% 
        pull(uid)
      # mask (NA) the responses to non-Swadesh items
      masked_resps <- fitted$model@Data$data
      masked_resps[,unselected_item_ids] = NA
      rand_fscores <- fscores(fitted$model, response.pattern=masked_resps)[,1] # ToDo: rerun with method="MAP" (slower than EAP?)
      tmp <- na.omit(data.frame(cbind(full_fscores_lang, swad_fscores, full_sumscores, 
                                      rand_fscores, rand_sumscores)))
      list(full_theta_vs_rand_sum = cor(tmp$rand_sumscores, tmp$full_fscores_lang),
           full_theta_vs_rand_theta = cor(tmp$rand_fscores, tmp$full_fscores_lang))
  }) 
  
  
  full_theta_vs_rand_sum = mean(unlist(rand_theta_cors["full_theta_vs_rand_sum",]))
  full_theta_vs_rand_theta = mean(unlist(rand_theta_cors["full_theta_vs_rand_theta",])) 
  # ToDo: save variance?
  
  theta_comps <- bind_rows(theta_comps, tibble(
    full_theta_vs_swad_theta=full_theta_vs_swad_theta,
    full_sum_vs_swad_theta=full_sum_vs_swad_theta,
    full_sum_vs_full_theta=full_sum_vs_full_theta,
    full_theta_vs_rand_sum=full_theta_vs_rand_sum,
    full_theta_vs_rand_theta=full_theta_vs_rand_theta 
  )) # full_sum_vs_rand_theta ?
  
  theta_comps
}


saveRDS(theta_comps, "data/full_vs_swadesh_fscores_allforms.rds")
```

(A few languages have fscore estimates fail to converge, resulting in mismatched vector lengths..need to label data rows with participant IDs and match up..)

```{r}
theta_comps <- readRDS("data/full_vs_swadesh_fscores_allforms.rds")

theta_comps |> arrange(desc(full_sum_vs_swad_theta)) |> kableExtra::kable(digits=3) 
```

Fscore T-tests:

```{r}
t.test(atanh(theta_comps$full_theta_vs_swad_theta), atanh(theta_comps$full_theta_vs_rand_theta))

t.test(atanh(theta_comps$full_sum_vs_swad_theta), atanh(theta_comps$full_sum_vs_full_theta))
```

Not significantly different (hooray / awww).


T-tests:

Swadesh is not significantly different than random
```{r}
t.test(gen_res_sum |> filter(sublist == "Swadesh") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)
```

```{r}
t.test(gen_res_sum |> filter(sublist == "Swadesh") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```

Swadesh is significantly easier than all items
```{r}
t.test(swadesh_sublist$mean_d,
       prod_sum$mean_d)
```


## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. First, we look at similarities across all IRT parameters, and then we focus in on the Swadesh candidates.

```{r, echo=F, fig.width=8, fig.height=8}
get_xling_difficulty_similarity <- function(xldf) {
  dif_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
  dif_sims <- tibble()
  colnames(dif_cors) = languages
  rownames(dif_cors) = languages

  for(l1 in languages) {
    for(l2 in languages) {
      tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
        select(uni_lemma, category, category, language, d) %>% # uid, 
        group_by(uni_lemma, language) %>%
        slice(1) %>% 
        pivot_wider(names_from = language, values_from = d) %>%
        drop_na()
      dif_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
      dif_sims <- bind_rows(dif_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
    }
  }
  return(dif_cors)
}

dif_cors <- get_xling_difficulty_similarity(xldf_clean)

Colors = brewer.pal(11,"Spectral")
diag(dif_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)")
heatmap.2(dif_cors, col=Colors)
```

### Similarity in Swadesh item parameters

```{r, echo=F, fig.width=8, fig.height=8}
swad_dif_cors <- get_xling_difficulty_similarity(xldf_clean %>% 
                                              filter(is.element(uni_lemma, swadesh_sublist$uni_lemma)))

heatmap.2(swad_dif_cors, col=Colors)
```

